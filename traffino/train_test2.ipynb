{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test for train ###\n",
    "# 230829\n",
    "# dataset 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\NGN\\\\dev\\\\Traffino\\\\TRAFFINO')\n",
    "import argparse\n",
    "import gc\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from traffino.data.loader import data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from losses import gan_g_loss, gan_d_loss, l2_loss\n",
    "from losses import displacement_error, final_displacement_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from traffino.models import TrajectoryGenerator, TrajectoryDiscriminator\n",
    "from traffino.utils import int_tuple, bool_flag, get_total_norm\n",
    "from traffino.utils import relative_to_abs, get_dset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True # cudnn의 benchmark를 통해 최적 backend 연산을 찾는 flag를 true로 하겠음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "FORMAT = '[%(levelname)s: %(filename)s: %(lineno)4d]: %(message)s'\n",
    "logging.basicConfig(level=logging.INFO, format=FORMAT, stream=sys.stdout)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = parser.parse_args()\n",
    "# # Dataset options\n",
    "# parser.add_argument('--dataset_name', default='zara1', type=str)\n",
    "# parser.add_argument('--delim', default=' ')\n",
    "# parser.add_argument('--loader_num_workers', default=4, type=int)\n",
    "# parser.add_argument('--obs_len', default=8, type=int)\n",
    "# parser.add_argument('--pred_len', default=8, type=int)\n",
    "# parser.add_argument('--skip', default=1, type=int)\n",
    "\n",
    "# # Optimization\n",
    "# parser.add_argument('--batch_size', default=64, type=int)\n",
    "# parser.add_argument('--num_iterations', default=10000, type=int)\n",
    "# parser.add_argument('--num_epochs', default=200, type=int)\n",
    "\n",
    "# # Model Options\n",
    "# parser.add_argument('--embedding_dim', default=64, type=int)\n",
    "# parser.add_argument('--num_layers', default=1, type=int)\n",
    "# parser.add_argument('--dropout', default=0, type=float)\n",
    "# parser.add_argument('--batch_norm', default=0, type=bool_flag)\n",
    "# parser.add_argument('--mlp_dim', default=1024, type=int)\n",
    "\n",
    "# # Generator Options\n",
    "# parser.add_argument('--encoder_h_dim_g', default=64, type=int)\n",
    "# parser.add_argument('--decoder_h_dim_g', default=128, type=int)\n",
    "# parser.add_argument('--noise_dim', default=None, type=int_tuple)\n",
    "# parser.add_argument('--noise_type', default='gaussian')\n",
    "# parser.add_argument('--noise_mix_type', default='ped')\n",
    "# parser.add_argument('--clipping_threshold_g', default=0, type=float)\n",
    "# parser.add_argument('--g_learning_rate', default=5e-4, type=float)\n",
    "# parser.add_argument('--g_steps', default=1, type=int)\n",
    "\n",
    "# # Pooling Options\n",
    "# parser.add_argument('--pooling_type', default='pool_net')\n",
    "# parser.add_argument('--pool_every_timestep', default=1, type=bool_flag)\n",
    "\n",
    "# # Pool Net Option\n",
    "# parser.add_argument('--bottleneck_dim', default=1024, type=int)\n",
    "\n",
    "# # Social Pooling Options\n",
    "# parser.add_argument('--neighborhood_size', default=2.0, type=float)\n",
    "# parser.add_argument('--grid_size', default=8, type=int)\n",
    "\n",
    "# # Discriminator Options\n",
    "# parser.add_argument('--d_type', default='local', type=str)\n",
    "# parser.add_argument('--encoder_h_dim_d', default=64, type=int)\n",
    "# parser.add_argument('--d_learning_rate', default=5e-4, type=float)\n",
    "# parser.add_argument('--d_steps', default=2, type=int)\n",
    "# parser.add_argument('--clipping_threshold_d', default=0, type=float)\n",
    "\n",
    "# # Loss Options\n",
    "# parser.add_argument('--l2_loss_weight', default=0, type=float)\n",
    "# parser.add_argument('--best_k', default=1, type=int)\n",
    "\n",
    "# # Output\n",
    "# parser.add_argument('--output_dir', default=os.getcwd())\n",
    "# parser.add_argument('--print_every', default=5, type=int)\n",
    "# parser.add_argument('--checkpoint_every', default=100, type=int)\n",
    "# parser.add_argument('--checkpoint_name', default='checkpoint')\n",
    "# parser.add_argument('--checkpoint_start_from', default=None)\n",
    "# parser.add_argument('--restore_from_checkpoint', default=1, type=int)\n",
    "# parser.add_argument('--num_samples_check', default=5000, type=int)\n",
    "\n",
    "# # Misc\n",
    "# parser.add_argument('--use_gpu', default=1, type=int)\n",
    "# parser.add_argument('--timing', default=0, type=int)\n",
    "# parser.add_argument('--gpu_num', default=\"0\", type=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "class CreateArg():\n",
    "    def __init__(self):\n",
    "        # Dataset options\n",
    "        self.dataset_name = 'waterloo'\n",
    "        self.delim = '\\t'\n",
    "        self.loader_num_workers = 4\n",
    "        self.obs_len = 8\n",
    "        self.pred_len = 8\n",
    "        self.skip = 1\n",
    "        # Optimization\n",
    "        self.batch_size = 64\n",
    "        self.num_iterations = 10000\n",
    "        self.num_epochs = 200                      \n",
    "        # Model Options\n",
    "        self.embedding_dim = 64\n",
    "        self.num_layers = 1\n",
    "        self.dropout = 0.0\n",
    "        self.batch_norm = 0 \n",
    "        self.mlp_dim = 1024\n",
    "        # self.default_backbone= 'resnet18'\n",
    "                                    \n",
    "        # Generator Options\n",
    "        self.encoder_h_dim_g = 64\n",
    "        self.decoder_h_dim_g = 128\n",
    "        self.noise_dim : Tuple[int] = (0, 0) # default=None # type=int_tuple\n",
    "        self.noise_type = 'gaussian'\n",
    "        self.noise_mix_type = 'ped'\n",
    "        self.clipping_threshold_g = 0 # type=float\n",
    "        self.g_learning_rate = 5e-4 # type=float \n",
    "        self.g_steps = 1\n",
    "\n",
    "        # Pooling Options\n",
    "        self.pooling_type = 'pool_net' \n",
    "        self.pool_every_timestep = 1 # type=bool_flag\n",
    "\n",
    "        # Pool Net Option\n",
    "        self.bottleneck_dim = 1024 # type=int\n",
    "\n",
    "        # Social Pooling Options\n",
    "        self.neighborhood_size = 1024 # type=float\n",
    "        self.grid_size = 8 # type=int\n",
    "\n",
    "        # Discriminator Options\n",
    "        self.d_type = 'local' # type=str\n",
    "        self.encoder_h_dim_d = 64 # type=int\n",
    "        self.d_learning_rate = 5e-4 # type=float\n",
    "        self.d_steps = 2 # type=int        \n",
    "        self.clipping_threshold_d = 0 # type=float  \n",
    "\n",
    "        # Loss Options\n",
    "        self.l2_loss_weight = 0 # type=float \n",
    "        self.best_k = 1 # type=int \n",
    "\n",
    "        # Output\n",
    "        self.output_dir = os.getcwd()\n",
    "        self.print_every = 5 # type=int\n",
    "        self.checkpoint_every = 100 # type=int\n",
    "        self.checkpoint_name = 'checkpoint' \n",
    "        self.checkpoint_start_from = None\n",
    "        self.restore_from_checkpoint = 1 # type=int\n",
    "        self.num_samples_check = 5000 # type=int        \n",
    "\n",
    "        # Misc\n",
    "        self.use_gpu = 1 # type=int\n",
    "        self.timing = 0 # type=int\n",
    "        self.gpu_num = \"0\" # type=str   \n",
    "\n",
    "\n",
    "args = CreateArg() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(args.use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "\n",
    "\n",
    "def get_dtypes(args):\n",
    "    long_dtype = torch.LongTensor\n",
    "    float_dtype = torch.FloatTensor\n",
    "    if args.use_gpu == 1:\n",
    "    # use_gpu == 1:\n",
    "        long_dtype = torch.cuda.LongTensor\n",
    "        float_dtype = torch.cuda.FloatTensor\n",
    "    return long_dtype, float_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_dtype, float_dtype = get_dtypes(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets\\waterloo\\val\n"
     ]
    }
   ],
   "source": [
    "# train_path = get_dset_path(args.dataset_name, 'train') # dset_name, dset_type\n",
    "# print(train_path) # datasets\\waterloo\\train\n",
    "train_path = 'C:\\\\Users\\\\NGN\\\\dev\\\\Traffino\\\\TRAFFINO\\\\traffino\\\\datasets\\\\waterloo\\\\train'\n",
    "val_path = get_dset_path(args.dataset_name, 'val')\n",
    "print(val_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 불러오기\n",
    "```python\n",
    "def data_loader(args, path):\n",
    "    dset = TrajectoryDataset(\n",
    "        path,\n",
    "        obs_len=args.obs_len,\n",
    "        pred_len=args.pred_len,\n",
    "        skip=args.skip,\n",
    "        delim=args.delim)\n",
    "\n",
    "    loader = DataLoader(\n",
    "        dset,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=False,\n",
    "        # shuffle=True,\n",
    "        num_workers=args.loader_num_workers,\n",
    "        collate_fn=seq_collate)\n",
    "    return dset, loader\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO: 3988962490.py:    1]: Initializing train dataset\n",
      "['0769_prep.txt']\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Initializing train dataset\")\n",
    "\n",
    "train_dset, train_loader = data_loader(args, train_path) # train_dset은 TrajectoryDataset, train_loader는 DataLoader\n",
    "# logger.info(\"Initializing val dataset\")\n",
    "# _, val_loader = data_loader(args, val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "712"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dset) # self.num_seq (727)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712\n"
     ]
    }
   ],
   "source": [
    "print(train_dset.num_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO: 2378675245.py:    6]: There are 5.5625 iterations per epoch\n"
     ]
    }
   ],
   "source": [
    "iterations_per_epoch = len(train_dset) / args.batch_size / args.d_steps\n",
    "if args.num_epochs:\n",
    "    args.num_iterations = int(iterations_per_epoch * args.num_epochs)\n",
    "\n",
    "logger.info(\n",
    "    'There are {} iterations per epoch'.format(iterations_per_epoch)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = TrajectoryGenerator(\n",
    "    obs_len=args.obs_len,\n",
    "    pred_len=args.pred_len,\n",
    "    embedding_dim=args.embedding_dim,\n",
    "    encoder_h_dim=args.encoder_h_dim_g,\n",
    "    decoder_h_dim=args.decoder_h_dim_g,\n",
    "    mlp_dim=args.mlp_dim,\n",
    "    num_layers=args.num_layers,\n",
    "    noise_dim=args.noise_dim,\n",
    "    bottleneck_dim=args.bottleneck_dim,\n",
    "    noise_type=args.noise_type,\n",
    "    noise_mix_type=args.noise_mix_type,\n",
    "    pooling_type=args.pooling_type,\n",
    "    pool_every_timestep=args.pool_every_timestep,\n",
    "    dropout=args.dropout,\n",
    "    activation = 'relu',\n",
    "    batch_norm = args.batch_norm,\n",
    "    neighborhood_size=args.neighborhood_size,\n",
    "    # default_backbone = args.default_backbone\n",
    "    # grid_size=args.grid_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO: 1295372059.py:    3]: Here is the generator:\n",
      "[INFO: 1295372059.py:    4]: TrajectoryGenerator(\n",
      "  (encoder): TrajEncoder(\n",
      "    (encoder): LSTM(64, 64)\n",
      "    (spatial_embedding): Linear(in_features=2, out_features=64, bias=True)\n",
      "  )\n",
      "  (encoder2): StateEncoder(\n",
      "    (encoder): LSTM(64, 64)\n",
      "    (spatial_embedding): Linear(in_features=4, out_features=64, bias=True)\n",
      "  )\n",
      "  (sft): SceneFusionTraffic(\n",
      "    (backbone): ResNetBackbone(\n",
      "      (backbone): Sequential(\n",
      "        (0): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "        (3): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
      "        (4): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (5): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (6): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (7): Sequential(\n",
      "          (0): BasicBlock(\n",
      "            (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (downsample): Sequential(\n",
      "              (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "              (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            )\n",
      "          )\n",
      "          (1): BasicBlock(\n",
      "            (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (relu): ReLU(inplace=True)\n",
      "            (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "            (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          )\n",
      "        )\n",
      "        (8): AvgPool2d(kernel_size=7, stride=1, padding=0)\n",
      "      )\n",
      "    )\n",
      "    (fc1): Linear(in_features=295937, out_features=4096, bias=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (decoder): LSTM(64, 128)\n",
      "    (spatial_embedding): Linear(in_features=2, out_features=64, bias=True)\n",
      "    (hidden2pos): Linear(in_features=128, out_features=2, bias=True)\n",
      "    (pool_net): PoolHiddenNet(\n",
      "      (spatial_embedding): Linear(in_features=2, out_features=64, bias=True)\n",
      "      (mlp_pre_pool): Sequential(\n",
      "        (0): Linear(in_features=192, out_features=512, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        (3): ReLU()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (pool_net): PoolHiddenNet(\n",
      "    (spatial_embedding): Linear(in_features=2, out_features=64, bias=True)\n",
      "    (mlp_pre_pool): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=512, out_features=1024, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (mlp_decoder_context): Sequential(\n",
      "    (0): Linear(in_features=2112, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "generator.apply(init_weights)\n",
    "generator.type(float_dtype).train()\n",
    "logger.info('Here is the generator:')\n",
    "logger.info(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = TrajectoryDiscriminator(\n",
    "    obs_len=args.obs_len,\n",
    "    pred_len=args.pred_len,\n",
    "    embedding_dim=args.embedding_dim,\n",
    "    h_dim=args.encoder_h_dim_d,\n",
    "    mlp_dim=args.mlp_dim,\n",
    "    num_layers=args.num_layers,\n",
    "    dropout=args.dropout,\n",
    "    batch_norm=args.batch_norm,\n",
    "    d_type=args.d_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO: 2576673517.py:    3]: Here is the discriminator:\n",
      "[INFO: 2576673517.py:    4]: TrajectoryDiscriminator(\n",
      "  (encoder): TrajEncoder(\n",
      "    (encoder): LSTM(64, 64)\n",
      "    (spatial_embedding): Linear(in_features=2, out_features=64, bias=True)\n",
      "  )\n",
      "  (real_classifier): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=1, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "discriminator.apply(init_weights)\n",
    "discriminator.type(float_dtype).train()\n",
    "logger.info('Here is the discriminator:')\n",
    "logger.info(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_loss_fn = gan_g_loss\n",
    "d_loss_fn = gan_d_loss\n",
    "\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=args.g_learning_rate)\n",
    "optimizer_d = optim.Adam(\n",
    "    discriminator.parameters(), lr=args.d_learning_rate\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe restore from checkpoint\n",
    "restore_path = None\n",
    "if args.checkpoint_start_from is not None:\n",
    "    restore_path = args.checkpoint_start_from\n",
    "elif args.restore_from_checkpoint == 1:\n",
    "    restore_path = os.path.join(args.output_dir,\n",
    "                                '%s_with_model.pt' % args.checkpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if restore_path is not None and os.path.isfile(restore_path): # restore 할 파일이 있으면\n",
    "    logger.info('Restoring from checkpoint {}'.format(restore_path))\n",
    "    checkpoint = torch.load(restore_path)\n",
    "    generator.load_state_dict(checkpoint['g_state'])\n",
    "    discriminator.load_state_dict(checkpoint['d_state'])\n",
    "    optimizer_g.load_state_dict(checkpoint['g_optim_state'])\n",
    "    optimizer_d.load_state_dict(checkpoint['d_optim_state'])\n",
    "    t = checkpoint['counters']['t']\n",
    "    epoch = checkpoint['counters']['epoch']\n",
    "    checkpoint['restore_ts'].append(t)\n",
    "else:\n",
    "    # Starting from scratch, so initialize checkpoint data structure\n",
    "    t, epoch = 0, 0\n",
    "    checkpoint = {\n",
    "        'args': args.__dict__,\n",
    "        'G_losses': defaultdict(list),\n",
    "        'D_losses': defaultdict(list),\n",
    "        'losses_ts': [],\n",
    "        'metrics_val': defaultdict(list),\n",
    "        'metrics_train': defaultdict(list),\n",
    "        'sample_ts': [],\n",
    "        'restore_ts': [],\n",
    "        'norm_g': [],\n",
    "        'norm_d': [],\n",
    "        'counters': {\n",
    "            't': None,\n",
    "            'epoch': None,\n",
    "        },\n",
    "        'g_state': None,\n",
    "        'g_optim_state': None,\n",
    "        'd_state': None,\n",
    "        'd_optim_state': None,\n",
    "        'g_best_state': None,\n",
    "        'd_best_state': None,\n",
    "        'best_t': None,\n",
    "        'g_best_nl_state': None,\n",
    "        'd_best_state_nl': None,\n",
    "        'best_t_nl': None,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO: 2424934719.py:    7]: Starting epoch 2\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "forward() missing 2 required positional arguments: 'image_tensor' and 'traffic_light'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28044\\2424934719.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m             losses_d = discriminator_step(args, batch, generator,\n\u001b[0;32m     20\u001b[0m                                             \u001b[0mdiscriminator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_loss_fn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m                                             optimizer_d)\n\u001b[0m\u001b[0;32m     22\u001b[0m             checkpoint['norm_d'].append(\n\u001b[0;32m     23\u001b[0m                 get_total_norm(discriminator.parameters()))\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_28044\\3294284160.py\u001b[0m in \u001b[0;36mdiscriminator_step\u001b[1;34m(args, batch, generator, discriminator, d_loss_fn, optimizer_d)\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred_traj_gt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mgenerator_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobs_traj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobs_traj_rel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mseq_start_end\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0mpred_traj_fake_rel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgenerator_out\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\NGN\\anaconda3\\envs\\traffino\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: forward() missing 2 required positional arguments: 'image_tensor' and 'traffic_light'"
     ]
    }
   ],
   "source": [
    "t0 = None\n",
    "while t < args.num_iterations: # 10000\n",
    "    gc.collect()\n",
    "    d_steps_left = args.d_steps # 2\n",
    "    g_steps_left = args.g_steps # 1\n",
    "    epoch += 1\n",
    "    logger.info('Starting epoch {}'.format(epoch))\n",
    "    for batch in train_loader:\n",
    "        if args.timing == 1: # default = 0\n",
    "            torch.cuda.synchronize()\n",
    "            t1 = time.time()\n",
    "\n",
    "        # Decide whether to use the batch for stepping on discriminator or\n",
    "        # generator; an iteration consists of args.d_steps steps on the\n",
    "        # discriminator followed by args.g_steps steps on the generator.\n",
    "        \n",
    "        if d_steps_left > 0:\n",
    "            step_type = 'd'\n",
    "            losses_d = discriminator_step(args, batch, generator,\n",
    "                                            discriminator, d_loss_fn,\n",
    "                                            optimizer_d)\n",
    "            checkpoint['norm_d'].append(\n",
    "                get_total_norm(discriminator.parameters()))\n",
    "            d_steps_left -= 1\n",
    "            \n",
    "        elif g_steps_left > 0:\n",
    "            step_type = 'g'\n",
    "            losses_g = generator_step(args, batch, generator,\n",
    "                                        discriminator, g_loss_fn, # g_loss_fn = gan_g_loss\n",
    "                                        optimizer_g)\n",
    "            \n",
    "            checkpoint['norm_g'].append(\n",
    "                get_total_norm(generator.parameters())\n",
    "            )\n",
    "            g_steps_left -= 1\n",
    "\n",
    "        if args.timing == 1:\n",
    "            torch.cuda.synchronize()\n",
    "            t2 = time.time()\n",
    "            logger.info('{} step took {}'.format(step_type, t2 - t1))\n",
    "\n",
    "        # Skip the rest if we are not at the end of an iteration\n",
    "        if d_steps_left > 0 or g_steps_left > 0:\n",
    "            continue\n",
    "\n",
    "        if args.timing == 1:\n",
    "            if t0 is not None:\n",
    "                logger.info('Interation {} took {}'.format(\n",
    "                    t - 1, time.time() - t0\n",
    "                ))\n",
    "            t0 = time.time()\n",
    "\n",
    "        # Maybe save loss\n",
    "        if t % args.print_every == 0:\n",
    "            logger.info('t = {} / {}'.format(t + 1, args.num_iterations))\n",
    "            for k, v in sorted(losses_d.items()):\n",
    "                logger.info('  [D] {}: {:.3f}'.format(k, v))\n",
    "                checkpoint['D_losses'][k].append(v)\n",
    "            for k, v in sorted(losses_g.items()):\n",
    "                logger.info('  [G] {}: {:.3f}'.format(k, v))\n",
    "                checkpoint['G_losses'][k].append(v)\n",
    "            checkpoint['losses_ts'].append(t)\n",
    "\n",
    "        # Maybe save a checkpoint\n",
    "        if t > 0 and t % args.checkpoint_every == 0:\n",
    "            checkpoint['counters']['t'] = t\n",
    "            checkpoint['counters']['epoch'] = epoch\n",
    "            checkpoint['sample_ts'].append(t)\n",
    "\n",
    "            # Check stats on the validation set\n",
    "            logger.info('Checking stats on val ...')\n",
    "            metrics_val = check_accuracy(\n",
    "                args, val_loader, generator, discriminator, d_loss_fn\n",
    "            )\n",
    "            logger.info('Checking stats on train ...')\n",
    "            metrics_train = check_accuracy(\n",
    "                args, train_loader, generator, discriminator,\n",
    "                d_loss_fn, limit=True\n",
    "            )\n",
    "\n",
    "            for k, v in sorted(metrics_val.items()):\n",
    "                logger.info('  [val] {}: {:.3f}'.format(k, v))\n",
    "                checkpoint['metrics_val'][k].append(v)\n",
    "                \n",
    "            for k, v in sorted(metrics_train.items()):\n",
    "                logger.info('  [train] {}: {:.3f}'.format(k, v))\n",
    "                checkpoint['metrics_train'][k].append(v)\n",
    "\n",
    "            min_ade = min(checkpoint['metrics_val']['ade'])\n",
    "            min_ade_nl = min(checkpoint['metrics_val']['ade_nl'])\n",
    "\n",
    "            if metrics_val['ade'] == min_ade:\n",
    "                logger.info('New low for avg_disp_error')\n",
    "                checkpoint['best_t'] = t\n",
    "                checkpoint['g_best_state'] = generator.state_dict()\n",
    "                checkpoint['d_best_state'] = discriminator.state_dict()\n",
    "\n",
    "            if metrics_val['ade_nl'] == min_ade_nl:\n",
    "                logger.info('New low for avg_disp_error_nl')\n",
    "                checkpoint['best_t_nl'] = t\n",
    "                checkpoint['g_best_nl_state'] = generator.state_dict()\n",
    "                checkpoint['d_best_nl_state'] = discriminator.state_dict()\n",
    "\n",
    "            # Save another checkpoint with model weights and\n",
    "            # optimizer state\n",
    "            checkpoint['g_state'] = generator.state_dict()\n",
    "            checkpoint['g_optim_state'] = optimizer_g.state_dict()\n",
    "            checkpoint['d_state'] = discriminator.state_dict()\n",
    "            checkpoint['d_optim_state'] = optimizer_d.state_dict()\n",
    "            \n",
    "            checkpoint_path = os.path.join(\n",
    "                args.output_dir, '%s_with_model.pt' % args.checkpoint_name\n",
    "            )\n",
    "            \n",
    "            logger.info('Saving checkpoint to {}'.format(checkpoint_path))\n",
    "            torch.save(checkpoint, checkpoint_path)\n",
    "            logger.info('Done.')\n",
    "\n",
    "            # Save a checkpoint with no model weights by making a shallow\n",
    "            # copy of the checkpoint excluding some items\n",
    "            \n",
    "            checkpoint_path = os.path.join(\n",
    "                args.output_dir, '%s_no_model.pt' % args.checkpoint_name)\n",
    "            \n",
    "            logger.info('Saving checkpoint to {}'.format(checkpoint_path))\n",
    "            \n",
    "            key_blacklist = [\n",
    "                'g_state', 'd_state', 'g_best_state', 'g_best_nl_state',\n",
    "                'g_optim_state', 'd_optim_state', 'd_best_state',\n",
    "                'd_best_nl_state'\n",
    "            ]\n",
    "            \n",
    "            small_checkpoint = {}\n",
    "            for k, v in checkpoint.items():\n",
    "                if k not in key_blacklist:\n",
    "                    small_checkpoint[k] = v\n",
    "            torch.save(small_checkpoint, checkpoint_path)\n",
    "            logger.info('Done.')\n",
    "\n",
    "        t += 1\n",
    "        d_steps_left = args.d_steps\n",
    "        g_steps_left = args.g_steps\n",
    "        if t >= args.num_iterations:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_step(\n",
    "    args, batch, generator, discriminator, d_loss_fn, optimizer_d\n",
    "):\n",
    "    batch = [tensor.cuda() for tensor in batch]\n",
    "    (obs_traj, _, _, pred_traj_gt, _, _, obs_traj_rel, _, _, pred_traj_gt_rel, _, _, non_linear_ped,\n",
    "     loss_mask, seq_start_end) = batch\n",
    "    losses = {}\n",
    "    loss = torch.zeros(1).to(pred_traj_gt)\n",
    "\n",
    "    generator_out = generator(obs_traj, obs_traj_rel, seq_start_end)\n",
    "\n",
    "    pred_traj_fake_rel = generator_out\n",
    "    pred_traj_fake = relative_to_abs(pred_traj_fake_rel, obs_traj[-1])\n",
    "\n",
    "    traj_real = torch.cat([obs_traj, pred_traj_gt], dim=0)\n",
    "    traj_real_rel = torch.cat([obs_traj_rel, pred_traj_gt_rel], dim=0)\n",
    "    traj_fake = torch.cat([obs_traj, pred_traj_fake], dim=0)\n",
    "    traj_fake_rel = torch.cat([obs_traj_rel, pred_traj_fake_rel], dim=0)\n",
    "\n",
    "    scores_fake = discriminator(traj_fake, traj_fake_rel, seq_start_end)\n",
    "    scores_real = discriminator(traj_real, traj_real_rel, seq_start_end)\n",
    "\n",
    "    # Compute loss with optional gradient penalty\n",
    "    data_loss = d_loss_fn(scores_real, scores_fake)\n",
    "    losses['D_data_loss'] = data_loss.item()\n",
    "    loss += data_loss\n",
    "    losses['D_total_loss'] = loss.item()\n",
    "\n",
    "    optimizer_d.zero_grad()\n",
    "    loss.backward()\n",
    "    if args.clipping_threshold_d > 0:\n",
    "        nn.utils.clip_grad_norm_(discriminator.parameters(),\n",
    "                                 args.clipping_threshold_d)\n",
    "    optimizer_d.step()\n",
    "\n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_step(\n",
    "    args, batch, generator, discriminator, g_loss_fn, optimizer_g\n",
    "):\n",
    "    batch = [tensor.cuda() for tensor in batch]\n",
    "    (obs_traj, obs_state, obs_traffic, \n",
    "     pred_traj_gt, pred_state_gt, pred_traffic_gt, \n",
    "     obs_traj_rel, obs_state_rel, obs_traffic_rel,\n",
    "     pred_traj_gt_rel, pred_state_gt_rel, pred_traffic_gt_rel, \n",
    "     non_linear_ped,\n",
    "     loss_mask, seq_start_end) = batch\n",
    "    \n",
    "    losses = {}\n",
    "    loss = torch.zeros(1).to(pred_traj_gt)\n",
    "    g_l2_loss_rel = []\n",
    "\n",
    "    loss_mask = loss_mask[:, args.obs_len:]\n",
    "\n",
    "    for _ in range(args.best_k):\n",
    "        generator_out = generator(obs_traj, obs_traj_rel, seq_start_end,\n",
    "                                image_tensor, agent_state_vector, traffic_light\n",
    "                                  )\n",
    "\n",
    "        pred_traj_fake_rel = generator_out\n",
    "        pred_traj_fake = relative_to_abs(pred_traj_fake_rel, obs_traj[-1])\n",
    "\n",
    "        if args.l2_loss_weight > 0:\n",
    "            g_l2_loss_rel.append(args.l2_loss_weight * l2_loss(\n",
    "                pred_traj_fake_rel,\n",
    "                pred_traj_gt_rel,\n",
    "                loss_mask,\n",
    "                mode='raw'))\n",
    "\n",
    "    g_l2_loss_sum_rel = torch.zeros(1).to(pred_traj_gt)\n",
    "    if args.l2_loss_weight > 0:\n",
    "        g_l2_loss_rel = torch.stack(g_l2_loss_rel, dim=1)\n",
    "        for start, end in seq_start_end.data:\n",
    "            _g_l2_loss_rel = g_l2_loss_rel[start:end]\n",
    "            _g_l2_loss_rel = torch.sum(_g_l2_loss_rel, dim=0)\n",
    "            _g_l2_loss_rel = torch.min(_g_l2_loss_rel) / torch.sum(\n",
    "                loss_mask[start:end])\n",
    "            g_l2_loss_sum_rel += _g_l2_loss_rel\n",
    "        losses['G_l2_loss_rel'] = g_l2_loss_sum_rel.item()\n",
    "        loss += g_l2_loss_sum_rel\n",
    "\n",
    "    traj_fake = torch.cat([obs_traj, pred_traj_fake], dim=0)\n",
    "    traj_fake_rel = torch.cat([obs_traj_rel, pred_traj_fake_rel], dim=0)\n",
    "\n",
    "    scores_fake = discriminator(traj_fake, traj_fake_rel, seq_start_end)\n",
    "    discriminator_loss = g_loss_fn(scores_fake)\n",
    "\n",
    "    loss += discriminator_loss\n",
    "    losses['G_discriminator_loss'] = discriminator_loss.item()\n",
    "    losses['G_total_loss'] = loss.item()\n",
    "\n",
    "    optimizer_g.zero_grad()\n",
    "    loss.backward()\n",
    "    if args.clipping_threshold_g > 0:\n",
    "        nn.utils.clip_grad_norm_(\n",
    "            generator.parameters(), args.clipping_threshold_g\n",
    "        )\n",
    "    optimizer_g.step()\n",
    "\n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(\n",
    "    args, loader, generator, discriminator, d_loss_fn, limit=False\n",
    "):\n",
    "    d_losses = []\n",
    "    metrics = {}\n",
    "    g_l2_losses_abs, g_l2_losses_rel = ([],) * 2\n",
    "    disp_error, disp_error_l, disp_error_nl = ([],) * 3\n",
    "    f_disp_error, f_disp_error_l, f_disp_error_nl = ([],) * 3\n",
    "    total_traj, total_traj_l, total_traj_nl = 0, 0, 0\n",
    "    loss_mask_sum = 0\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = [tensor.cuda() for tensor in batch]\n",
    "            (obs_traj, pred_traj_gt, obs_traj_rel, pred_traj_gt_rel,\n",
    "             non_linear_ped, loss_mask, seq_start_end) = batch\n",
    "            linear_ped = 1 - non_linear_ped\n",
    "            loss_mask = loss_mask[:, args.obs_len:]\n",
    "\n",
    "            pred_traj_fake_rel = generator(\n",
    "                obs_traj, obs_traj_rel, seq_start_end\n",
    "            )\n",
    "            pred_traj_fake = relative_to_abs(pred_traj_fake_rel, obs_traj[-1])\n",
    "\n",
    "            g_l2_loss_abs, g_l2_loss_rel = cal_l2_losses(\n",
    "                pred_traj_gt, pred_traj_gt_rel, pred_traj_fake,\n",
    "                pred_traj_fake_rel, loss_mask\n",
    "            )\n",
    "            ade, ade_l, ade_nl = cal_ade(\n",
    "                pred_traj_gt, pred_traj_fake, linear_ped, non_linear_ped\n",
    "            )\n",
    "\n",
    "            fde, fde_l, fde_nl = cal_fde(\n",
    "                pred_traj_gt, pred_traj_fake, linear_ped, non_linear_ped\n",
    "            )\n",
    "\n",
    "            traj_real = torch.cat([obs_traj, pred_traj_gt], dim=0)\n",
    "            traj_real_rel = torch.cat([obs_traj_rel, pred_traj_gt_rel], dim=0)\n",
    "            traj_fake = torch.cat([obs_traj, pred_traj_fake], dim=0)\n",
    "            traj_fake_rel = torch.cat([obs_traj_rel, pred_traj_fake_rel], dim=0)\n",
    "\n",
    "            scores_fake = discriminator(traj_fake, traj_fake_rel, seq_start_end)\n",
    "            scores_real = discriminator(traj_real, traj_real_rel, seq_start_end)\n",
    "\n",
    "            d_loss = d_loss_fn(scores_real, scores_fake)\n",
    "            d_losses.append(d_loss.item())\n",
    "\n",
    "            g_l2_losses_abs.append(g_l2_loss_abs.item())\n",
    "            g_l2_losses_rel.append(g_l2_loss_rel.item())\n",
    "            disp_error.append(ade.item())\n",
    "            disp_error_l.append(ade_l.item())\n",
    "            disp_error_nl.append(ade_nl.item())\n",
    "            f_disp_error.append(fde.item())\n",
    "            f_disp_error_l.append(fde_l.item())\n",
    "            f_disp_error_nl.append(fde_nl.item())\n",
    "\n",
    "            loss_mask_sum += torch.numel(loss_mask.data)\n",
    "            total_traj += pred_traj_gt.size(1)\n",
    "            total_traj_l += torch.sum(linear_ped).item()\n",
    "            total_traj_nl += torch.sum(non_linear_ped).item()\n",
    "            if limit and total_traj >= args.num_samples_check:\n",
    "                break\n",
    "\n",
    "    metrics['d_loss'] = sum(d_losses) / len(d_losses)\n",
    "    metrics['g_l2_loss_abs'] = sum(g_l2_losses_abs) / loss_mask_sum\n",
    "    metrics['g_l2_loss_rel'] = sum(g_l2_losses_rel) / loss_mask_sum\n",
    "\n",
    "    metrics['ade'] = sum(disp_error) / (total_traj * args.pred_len)\n",
    "    metrics['fde'] = sum(f_disp_error) / total_traj\n",
    "    if total_traj_l != 0:\n",
    "        metrics['ade_l'] = sum(disp_error_l) / (total_traj_l * args.pred_len)\n",
    "        metrics['fde_l'] = sum(f_disp_error_l) / total_traj_l\n",
    "    else:\n",
    "        metrics['ade_l'] = 0\n",
    "        metrics['fde_l'] = 0\n",
    "    if total_traj_nl != 0:\n",
    "        metrics['ade_nl'] = sum(disp_error_nl) / (\n",
    "            total_traj_nl * args.pred_len)\n",
    "        metrics['fde_nl'] = sum(f_disp_error_nl) / total_traj_nl\n",
    "    else:\n",
    "        metrics['ade_nl'] = 0\n",
    "        metrics['fde_nl'] = 0\n",
    "\n",
    "    generator.train()\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def cal_l2_losses(\n",
    "    pred_traj_gt, pred_traj_gt_rel, pred_traj_fake, pred_traj_fake_rel,\n",
    "    loss_mask\n",
    "):\n",
    "    g_l2_loss_abs = l2_loss(\n",
    "        pred_traj_fake, pred_traj_gt, loss_mask, mode='sum'\n",
    "    )\n",
    "    g_l2_loss_rel = l2_loss(\n",
    "        pred_traj_fake_rel, pred_traj_gt_rel, loss_mask, mode='sum'\n",
    "    )\n",
    "    return g_l2_loss_abs, g_l2_loss_rel\n",
    "\n",
    "\n",
    "def cal_ade(pred_traj_gt, pred_traj_fake, linear_ped, non_linear_ped):\n",
    "    ade = displacement_error(pred_traj_fake, pred_traj_gt)\n",
    "    ade_l = displacement_error(pred_traj_fake, pred_traj_gt, linear_ped)\n",
    "    ade_nl = displacement_error(pred_traj_fake, pred_traj_gt, non_linear_ped)\n",
    "    return ade, ade_l, ade_nl\n",
    "\n",
    "\n",
    "def cal_fde(\n",
    "    pred_traj_gt, pred_traj_fake, linear_ped, non_linear_ped\n",
    "):\n",
    "    fde = final_displacement_error(pred_traj_fake[-1], pred_traj_gt[-1])\n",
    "    fde_l = final_displacement_error(\n",
    "        pred_traj_fake[-1], pred_traj_gt[-1], linear_ped\n",
    "    )\n",
    "    fde_nl = final_displacement_error(\n",
    "        pred_traj_fake[-1], pred_traj_gt[-1], non_linear_ped\n",
    "    )\n",
    "    return fde, fde_l, fde_nl"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "waterloo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
