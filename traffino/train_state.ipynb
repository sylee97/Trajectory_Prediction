{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test for train ###\n",
    "# 230829\n",
    "# dataset 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino')\n",
    "\n",
    "import argparse\n",
    "import gc\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from data.loader import data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from losses import gan_g_loss, gan_d_loss, l2_loss\n",
    "from losses import displacement_error, final_displacement_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from traffino.models_state import TrajectoryGenerator, TrajectoryDiscriminator\n",
    "from traffino.utils import int_tuple, bool_flag, get_total_norm\n",
    "from traffino.utils import relative_to_abs, get_dset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True # cudnn의 benchmark를 통해 최적 backend 연산을 찾는 flag를 true로 하겠음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "FORMAT = '[%(levelname)s: %(filename)s: %(lineno)4d]: %(message)s'\n",
    "logging.basicConfig(level=logging.INFO, format=FORMAT, stream=sys.stdout)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = parser.parse_args()\n",
    "# # Dataset options\n",
    "# parser.add_argument('--dataset_name', default='zara1', type=str)\n",
    "# parser.add_argument('--delim', default=' ')\n",
    "# parser.add_argument('--loader_num_workers', default=4, type=int)\n",
    "# parser.add_argument('--obs_len', default=8, type=int)\n",
    "# parser.add_argument('--pred_len', default=8, type=int)\n",
    "# parser.add_argument('--skip', default=1, type=int)\n",
    "\n",
    "# # Optimization\n",
    "# parser.add_argument('--batch_size', default=64, type=int)\n",
    "# parser.add_argument('--num_iterations', default=10000, type=int)\n",
    "# parser.add_argument('--num_epochs', default=200, type=int)\n",
    "\n",
    "# # Model Options\n",
    "# parser.add_argument('--embedding_dim', default=64, type=int)\n",
    "# parser.add_argument('--num_layers', default=1, type=int)\n",
    "# parser.add_argument('--dropout', default=0, type=float)\n",
    "# parser.add_argument('--batch_norm', default=0, type=bool_flag)\n",
    "# parser.add_argument('--mlp_dim', default=1024, type=int)\n",
    "\n",
    "# # Generator Options\n",
    "# parser.add_argument('--encoder_h_dim_g', default=64, type=int)\n",
    "# parser.add_argument('--decoder_h_dim_g', default=128, type=int)\n",
    "# parser.add_argument('--noise_dim', default=None, type=int_tuple)\n",
    "# parser.add_argument('--noise_type', default='gaussian')\n",
    "# parser.add_argument('--noise_mix_type', default='ped')\n",
    "# parser.add_argument('--clipping_threshold_g', default=0, type=float)\n",
    "# parser.add_argument('--g_learning_rate', default=5e-4, type=float)\n",
    "# parser.add_argument('--g_steps', default=1, type=int)\n",
    "\n",
    "# # Pooling Options\n",
    "# parser.add_argument('--pooling_type', default='pool_net')\n",
    "# parser.add_argument('--pool_every_timestep', default=1, type=bool_flag)\n",
    "\n",
    "# # Pool Net Option\n",
    "# parser.add_argument('--bottleneck_dim', default=1024, type=int)\n",
    "\n",
    "# # Social Pooling Options\n",
    "# parser.add_argument('--neighborhood_size', default=2.0, type=float)\n",
    "# parser.add_argument('--grid_size', default=8, type=int)\n",
    "\n",
    "# # Discriminator Options\n",
    "# parser.add_argument('--d_type', default='local', type=str)\n",
    "# parser.add_argument('--encoder_h_dim_d', default=64, type=int)\n",
    "# parser.add_argument('--d_learning_rate', default=5e-4, type=float)\n",
    "# parser.add_argument('--d_steps', default=2, type=int)\n",
    "# parser.add_argument('--clipping_threshold_d', default=0, type=float)\n",
    "\n",
    "# # Loss Options\n",
    "# parser.add_argument('--l2_loss_weight', default=0, type=float)\n",
    "# parser.add_argument('--best_k', default=1, type=int)\n",
    "\n",
    "# # Output\n",
    "# parser.add_argument('--output_dir', default=os.getcwd())\n",
    "# parser.add_argument('--print_every', default=5, type=int)\n",
    "# parser.add_argument('--checkpoint_every', default=100, type=int)\n",
    "# parser.add_argument('--checkpoint_name', default='checkpoint')\n",
    "# parser.add_argument('--checkpoint_start_from', default=None)\n",
    "# parser.add_argument('--restore_from_checkpoint', default=1, type=int)\n",
    "# parser.add_argument('--num_samples_check', default=5000, type=int)\n",
    "\n",
    "# # Misc\n",
    "# parser.add_argument('--use_gpu', default=1, type=int)\n",
    "# parser.add_argument('--timing', default=0, type=int)\n",
    "# parser.add_argument('--gpu_num', default=\"0\", type=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "class CreateArg():\n",
    "    def __init__(self):\n",
    "        # Dataset options\n",
    "        self.dataset_name = 'waterloo'\n",
    "        self.delim = '\\t'\n",
    "        self.loader_num_workers = 4\n",
    "        self.obs_len = 8\n",
    "        self.pred_len = 8\n",
    "        self.skip = 1\n",
    "        # Optimization\n",
    "        self.batch_size = 4\n",
    "        self.num_iterations = 1000 # 10000\n",
    "        self.num_epochs = 50 # 200                     \n",
    "        # Model Options\n",
    "        self.embedding_dim = 64\n",
    "        self.num_layers = 1\n",
    "        self.dropout = 0.0\n",
    "        self.batch_norm = 0 \n",
    "        self.mlp_dim = 1024\n",
    "        # self.default_backbone= 'resnet18'\n",
    "                                    \n",
    "        # Generator Options\n",
    "        self.encoder_h_dim_g = 64\n",
    "        self.decoder_h_dim_g = 128\n",
    "        self.noise_dim : Tuple[int] = (0, 0) # default=None # type=int_tuple\n",
    "        self.noise_type = 'gaussian'\n",
    "        self.noise_mix_type = 'ped'\n",
    "        self.clipping_threshold_g = 0 # type=float\n",
    "        self.g_learning_rate = 5e-4 # type=float \n",
    "        self.g_steps = 1\n",
    "\n",
    "        # Pooling Options\n",
    "        self.pooling_type = 'pool_net' \n",
    "        self.pool_every_timestep = 1 # type=bool_flag\n",
    "\n",
    "        # Pool Net Option\n",
    "        self.bottleneck_dim = 1024 # type=int\n",
    "\n",
    "        # Social Pooling Options\n",
    "        self.neighborhood_size = 1024 # type=float\n",
    "        self.grid_size = 8 # type=int\n",
    "\n",
    "        # Discriminator Options\n",
    "        self.d_type = 'local' # type=str\n",
    "        self.encoder_h_dim_d = 64 # type=int\n",
    "        self.d_learning_rate = 5e-4 # type=float\n",
    "        self.d_steps = 2 # type=int        \n",
    "        self.clipping_threshold_d = 0 # type=float  \n",
    "\n",
    "        # Loss Options\n",
    "        self.l2_loss_weight = 0 # type=float \n",
    "        self.best_k = 1 # type=int \n",
    "\n",
    "        # Output\n",
    "        self.output_dir = os.getcwd()\n",
    "        self.print_every = 5 # type=int\n",
    "        self.checkpoint_every = 100 # type=int\n",
    "        self.checkpoint_name = 'checkpoint' \n",
    "        self.checkpoint_start_from = None\n",
    "        self.restore_from_checkpoint = 1 # type=int\n",
    "        self.num_samples_check = 5000 # type=int        \n",
    "\n",
    "        # Misc\n",
    "        self.use_gpu = 1 # type=int\n",
    "        self.timing = 0 # type=int\n",
    "        self.gpu_num = \"1\" # type=str   \n",
    "\n",
    "\n",
    "args = CreateArg() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(args.use_gpu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "\n",
    "\n",
    "def get_dtypes(args):\n",
    "    long_dtype = torch.LongTensor\n",
    "    float_dtype = torch.FloatTensor\n",
    "    if args.use_gpu == 1:\n",
    "    # use_gpu == 1:\n",
    "        long_dtype = torch.cuda.LongTensor\n",
    "        float_dtype = torch.cuda.FloatTensor\n",
    "    return long_dtype, float_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_dtype, float_dtype = get_dtypes(args)\n",
    "\n",
    "# def get_dset_path(dset_name, dset_type):\n",
    "#     _dir = os.path.dirname(__file__) # __file__ : 현재 수행중인 코드를 담고 있는 파일의 위치한 Path를 알려줌\n",
    "#     _dir = _dir.split(\"/\")[:-1]\n",
    "#     _dir = \"/\".join(_dir)\n",
    "#     return os.path.join(_dir, 'datasets', dset_name, dset_type)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 현재 폴더 : '/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino' \n",
    "\n",
    "# train_path = get_dset_path(args.dataset_name, 'train') # dset_name, dset_type\n",
    "# print(train_path) # /home/gpuadmin/dev/traj_pred/Trajectory_Prediction/datasets/waterloo/train\n",
    "\n",
    "train_path = '/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/train/'\n",
    "# val_path = get_dset_path(args.dataset_name, 'val')\n",
    "\n",
    "val_path = '/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/val/'\n",
    "# print(val_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset 불러오기\n",
    "```python\n",
    "def data_loader(args, path):\n",
    "    dset = TrajectoryDataset(\n",
    "        path,\n",
    "        obs_len=args.obs_len,\n",
    "        pred_len=args.pred_len,\n",
    "        skip=args.skip,\n",
    "        delim=args.delim)\n",
    "\n",
    "    loader = DataLoader(\n",
    "        dset,\n",
    "        batch_size=args.batch_size,\n",
    "        shuffle=False,\n",
    "        # shuffle=True,\n",
    "        num_workers=args.loader_num_workers,\n",
    "        collate_fn=seq_collate)\n",
    "    return dset, loader\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO: 74028204.py:    1]: Initializing train dataset\n",
      "['0780_prep.txt', '0771_prep.txt', '0776_prep.txt', '0775_prep.txt', '0778_prep.txt', '0777_prep.txt', '0770_prep.txt', '0769_prep.txt', '0779_prep.txt', '0781_prep.txt']\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/train/0769_prep.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/train2/0769_prep2.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/train2/0769_prep3.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/train/0770_prep.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/train2/0770_prep2.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/train2/0770_prep3.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/train/0771_prep.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/train2/0771_prep2.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/train2/0771_prep3.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/train/0775_prep.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/train2/0775_prep2.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/train2/0775_prep3.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/train/0776_prep.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/train2/0776_prep2.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/train2/0776_prep3.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/train/0777_prep.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/train2/0777_prep2.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/train2/0777_prep3.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/train/0778_prep.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/train2/0778_prep2.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/train2/0778_prep3.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/train/0779_prep.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/train2/0779_prep2.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/train2/0779_prep3.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/train/0780_prep.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/train2/0780_prep2.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/train2/0780_prep3.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/train/0781_prep.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/train2/0781_prep2.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/train2/0781_prep3.txt\n",
      "[INFO: 74028204.py:    4]: Initializing val dataset\n",
      "['0784_prep.txt', '0782_prep.txt', '0783_prep.txt']\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/val/0782_prep.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/val2/0782_prep2.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/val2/0782_prep3.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/val/0783_prep.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/val2/0783_prep2.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/val2/0783_prep3.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/val/0784_prep.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/val2/0784_prep2.txt\n",
      "/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/datasets/waterloo/val2/0784_prep3.txt\n"
     ]
    }
   ],
   "source": [
    "logger.info(\"Initializing train dataset\")\n",
    "train_dset, train_loader = data_loader(args, train_path) # train_dset은 TrajectoryDataset, train_loader는 DataLoader\n",
    "\n",
    "logger.info(\"Initializing val dataset\")\n",
    "_, val_loader = data_loader(args, val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6735"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_dset) # self.num_seq (727)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6735\n"
     ]
    }
   ],
   "source": [
    "print(train_dset.num_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO: 2378675245.py:    6]: There are 841.875 iterations per epoch\n"
     ]
    }
   ],
   "source": [
    "iterations_per_epoch = len(train_dset) / args.batch_size / args.d_steps\n",
    "if args.num_epochs:\n",
    "    args.num_iterations = int(iterations_per_epoch * args.num_epochs)\n",
    "\n",
    "logger.info(\n",
    "    'There are {} iterations per epoch'.format(iterations_per_epoch)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TrajectoryGenerator에서 generator instance 생성 (models.py)\n",
    "generator = TrajectoryGenerator(\n",
    "    obs_len=args.obs_len,\n",
    "    pred_len=args.pred_len,\n",
    "    embedding_dim=args.embedding_dim,\n",
    "    encoder_h_dim=args.encoder_h_dim_g,\n",
    "    decoder_h_dim=args.decoder_h_dim_g,\n",
    "    mlp_dim=args.mlp_dim,\n",
    "    num_layers=args.num_layers,\n",
    "    noise_dim=args.noise_dim,\n",
    "    bottleneck_dim=args.bottleneck_dim,\n",
    "    noise_type=args.noise_type,\n",
    "    noise_mix_type=args.noise_mix_type,\n",
    "    pooling_type=args.pooling_type,\n",
    "    pool_every_timestep=args.pool_every_timestep,\n",
    "    dropout=args.dropout,\n",
    "    activation = 'relu',\n",
    "    batch_norm = args.batch_norm,\n",
    "    neighborhood_size=args.neighborhood_size,\n",
    "    # grid_size=args.grid_size\n",
    "    )\n",
    "\n",
    "# def forward(self, obs_traj, obs_traj_rel, seq_start_end, \n",
    "#             obs_state, obs_state_rel,\n",
    "#             user_noise=None):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO: 1295372059.py:    3]: Here is the generator:\n",
      "[INFO: 1295372059.py:    4]: TrajectoryGenerator(\n",
      "  (encoder): TrajEncoder(\n",
      "    (encoder): LSTM(64, 64)\n",
      "    (spatial_embedding): Linear(in_features=2, out_features=64, bias=True)\n",
      "  )\n",
      "  (encoder2): StateEncoder(\n",
      "    (encoder): LSTM(64, 64)\n",
      "    (spatial_embedding): Linear(in_features=4, out_features=64, bias=True)\n",
      "  )\n",
      "  (decoder): Decoder(\n",
      "    (decoder): LSTM(64, 128)\n",
      "    (spatial_embedding): Linear(in_features=2, out_features=64, bias=True)\n",
      "    (hidden2pos): Linear(in_features=128, out_features=2, bias=True)\n",
      "    (pool_net): PoolHiddenNet(\n",
      "      (spatial_embedding): Linear(in_features=2, out_features=64, bias=True)\n",
      "      (mlp_pre_pool): Sequential(\n",
      "        (0): Linear(in_features=192, out_features=512, bias=True)\n",
      "        (1): ReLU()\n",
      "        (2): Linear(in_features=512, out_features=1024, bias=True)\n",
      "        (3): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (mlp): Sequential(\n",
      "      (0): Linear(in_features=1152, out_features=1024, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=1024, out_features=128, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (pool_net): PoolHiddenNet(\n",
      "    (spatial_embedding): Linear(in_features=2, out_features=64, bias=True)\n",
      "    (mlp_pre_pool): Sequential(\n",
      "      (0): Linear(in_features=128, out_features=512, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=512, out_features=1024, bias=True)\n",
      "      (3): ReLU()\n",
      "    )\n",
      "  )\n",
      "  (mlp_decoder_context): Sequential(\n",
      "    (0): Linear(in_features=1152, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=128, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "generator.apply(init_weights)\n",
    "generator.type(float_dtype).train()\n",
    "logger.info('Here is the generator:')\n",
    "logger.info(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = TrajectoryDiscriminator(\n",
    "    obs_len=args.obs_len,\n",
    "    pred_len=args.pred_len,\n",
    "    embedding_dim=args.embedding_dim,\n",
    "    h_dim=args.encoder_h_dim_d,\n",
    "    mlp_dim=args.mlp_dim,\n",
    "    num_layers=args.num_layers,\n",
    "    dropout=args.dropout,\n",
    "    batch_norm=args.batch_norm,\n",
    "    d_type=args.d_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO: 2576673517.py:    3]: Here is the discriminator:\n",
      "[INFO: 2576673517.py:    4]: TrajectoryDiscriminator(\n",
      "  (encoder): TrajEncoder(\n",
      "    (encoder): LSTM(64, 64)\n",
      "    (spatial_embedding): Linear(in_features=2, out_features=64, bias=True)\n",
      "  )\n",
      "  (real_classifier): Sequential(\n",
      "    (0): Linear(in_features=64, out_features=1024, bias=True)\n",
      "    (1): ReLU()\n",
      "    (2): Linear(in_features=1024, out_features=1, bias=True)\n",
      "    (3): ReLU()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "discriminator.apply(init_weights)\n",
    "discriminator.type(float_dtype).train()\n",
    "logger.info('Here is the discriminator:')\n",
    "logger.info(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_loss_fn = gan_g_loss\n",
    "d_loss_fn = gan_d_loss\n",
    "\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=args.g_learning_rate)\n",
    "optimizer_d = optim.Adam(\n",
    "    discriminator.parameters(), lr=args.d_learning_rate\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe restore from checkpoint\n",
    "restore_path = None\n",
    "if args.checkpoint_start_from is not None:\n",
    "    restore_path = args.checkpoint_start_from\n",
    "elif args.restore_from_checkpoint == 1:\n",
    "    restore_path = os.path.join(args.output_dir,\n",
    "                                '%s_with_model.pt' % args.checkpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO: 4073257687.py:    2]: Restoring from checkpoint /home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/checkpoint_with_model.pt\n"
     ]
    }
   ],
   "source": [
    "if restore_path is not None and os.path.isfile(restore_path): # restore 할 파일이 있으면\n",
    "    logger.info('Restoring from checkpoint {}'.format(restore_path))\n",
    "    checkpoint = torch.load(restore_path)\n",
    "    generator.load_state_dict(checkpoint['g_state'])\n",
    "    discriminator.load_state_dict(checkpoint['d_state'])\n",
    "    optimizer_g.load_state_dict(checkpoint['g_optim_state'])\n",
    "    optimizer_d.load_state_dict(checkpoint['d_optim_state'])\n",
    "    t = checkpoint['counters']['t']\n",
    "    epoch = checkpoint['counters']['epoch']\n",
    "    checkpoint['restore_ts'].append(t)\n",
    "else:\n",
    "    # Starting from scratch, so initialize checkpoint data structure\n",
    "    t, epoch = 0, 0\n",
    "    checkpoint = {\n",
    "        'args': args.__dict__,\n",
    "        'G_losses': defaultdict(list),\n",
    "        'D_losses': defaultdict(list),\n",
    "        'losses_ts': [],\n",
    "        'metrics_val': defaultdict(list),\n",
    "        'metrics_train': defaultdict(list),\n",
    "        'sample_ts': [],\n",
    "        'restore_ts': [],\n",
    "        'norm_g': [],\n",
    "        'norm_d': [],\n",
    "        'counters': {\n",
    "            't': None,\n",
    "            'epoch': None,\n",
    "        },\n",
    "        'g_state': None,\n",
    "        'g_optim_state': None,\n",
    "        'd_state': None,\n",
    "        'd_optim_state': None,\n",
    "        'g_best_state': None,\n",
    "        'd_best_state': None,\n",
    "        'best_t': None,\n",
    "        'g_best_nl_state': None,\n",
    "        'd_best_state_nl': None,\n",
    "        'best_t_nl': None,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42093\n"
     ]
    }
   ],
   "source": [
    "print(args.num_iterations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO: 2054027159.py:    7]: Starting epoch 76\n",
      "[INFO: 2054027159.py:   55]: t = 42001 / 42093\n",
      "[INFO: 2054027159.py:   57]:   [D] D_data_loss: 1.386\n",
      "[INFO: 2054027159.py:   57]:   [D] D_total_loss: 1.386\n",
      "[INFO: 2054027159.py:   60]:   [G] G_discriminator_loss: 0.693\n",
      "[INFO: 2054027159.py:   60]:   [G] G_total_loss: 0.693\n",
      "[INFO: 2054027159.py:   71]: Checking stats on val ...\n",
      "[INFO: 2054027159.py:   76]: Checking stats on train ...\n",
      "[INFO: 2054027159.py:   83]:   [val] ade: 12.736\n",
      "[INFO: 2054027159.py:   83]:   [val] ade_l: 19.724\n",
      "[INFO: 2054027159.py:   83]:   [val] ade_nl: 35.945\n",
      "[INFO: 2054027159.py:   83]:   [val] d_loss: 1.386\n",
      "[INFO: 2054027159.py:   83]:   [val] fde: 23.930\n",
      "[INFO: 2054027159.py:   83]:   [val] fde_l: 37.061\n",
      "[INFO: 2054027159.py:   83]:   [val] fde_nl: 67.539\n",
      "[INFO: 2054027159.py:   83]:   [val] g_l2_loss_abs: 78.615\n",
      "[INFO: 2054027159.py:   83]:   [val] g_l2_loss_rel: 78.615\n",
      "[INFO: 2054027159.py:   87]:   [train] ade: 12.725\n",
      "[INFO: 2054027159.py:   87]:   [train] ade_l: 20.743\n",
      "[INFO: 2054027159.py:   87]:   [train] ade_nl: 32.922\n",
      "[INFO: 2054027159.py:   87]:   [train] d_loss: 1.386\n",
      "[INFO: 2054027159.py:   87]:   [train] fde: 23.954\n",
      "[INFO: 2054027159.py:   87]:   [train] fde_l: 39.047\n",
      "[INFO: 2054027159.py:   87]:   [train] fde_nl: 61.973\n",
      "[INFO: 2054027159.py:   87]:   [train] g_l2_loss_abs: 79.198\n",
      "[INFO: 2054027159.py:   87]:   [train] g_l2_loss_rel: 79.198\n",
      "[INFO: 2054027159.py:  116]: Saving checkpoint to /home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/checkpoint_with_model.pt\n",
      "[INFO: 2054027159.py:  118]: Done.\n",
      "[INFO: 2054027159.py:  126]: Saving checkpoint to /home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino/checkpoint_no_model.pt\n",
      "[INFO: 2054027159.py:  139]: Done.\n",
      "[INFO: 2054027159.py:   55]: t = 42006 / 42093\n",
      "[INFO: 2054027159.py:   57]:   [D] D_data_loss: 1.386\n",
      "[INFO: 2054027159.py:   57]:   [D] D_total_loss: 1.386\n",
      "[INFO: 2054027159.py:   60]:   [G] G_discriminator_loss: 0.693\n",
      "[INFO: 2054027159.py:   60]:   [G] G_total_loss: 0.693\n",
      "[INFO: 2054027159.py:   55]: t = 42011 / 42093\n",
      "[INFO: 2054027159.py:   57]:   [D] D_data_loss: 1.386\n",
      "[INFO: 2054027159.py:   57]:   [D] D_total_loss: 1.386\n",
      "[INFO: 2054027159.py:   60]:   [G] G_discriminator_loss: 0.693\n",
      "[INFO: 2054027159.py:   60]:   [G] G_total_loss: 0.693\n",
      "[INFO: 2054027159.py:   55]: t = 42016 / 42093\n",
      "[INFO: 2054027159.py:   57]:   [D] D_data_loss: 1.386\n",
      "[INFO: 2054027159.py:   57]:   [D] D_total_loss: 1.386\n",
      "[INFO: 2054027159.py:   60]:   [G] G_discriminator_loss: 0.693\n",
      "[INFO: 2054027159.py:   60]:   [G] G_total_loss: 0.693\n",
      "[INFO: 2054027159.py:   55]: t = 42021 / 42093\n",
      "[INFO: 2054027159.py:   57]:   [D] D_data_loss: 1.386\n",
      "[INFO: 2054027159.py:   57]:   [D] D_total_loss: 1.386\n",
      "[INFO: 2054027159.py:   60]:   [G] G_discriminator_loss: 0.693\n",
      "[INFO: 2054027159.py:   60]:   [G] G_total_loss: 0.693\n",
      "[INFO: 2054027159.py:   55]: t = 42026 / 42093\n",
      "[INFO: 2054027159.py:   57]:   [D] D_data_loss: 1.386\n",
      "[INFO: 2054027159.py:   57]:   [D] D_total_loss: 1.386\n",
      "[INFO: 2054027159.py:   60]:   [G] G_discriminator_loss: 0.693\n",
      "[INFO: 2054027159.py:   60]:   [G] G_total_loss: 0.693\n",
      "[INFO: 2054027159.py:   55]: t = 42031 / 42093\n",
      "[INFO: 2054027159.py:   57]:   [D] D_data_loss: 1.386\n",
      "[INFO: 2054027159.py:   57]:   [D] D_total_loss: 1.386\n",
      "[INFO: 2054027159.py:   60]:   [G] G_discriminator_loss: 0.693\n",
      "[INFO: 2054027159.py:   60]:   [G] G_total_loss: 0.693\n",
      "[INFO: 2054027159.py:   55]: t = 42036 / 42093\n",
      "[INFO: 2054027159.py:   57]:   [D] D_data_loss: 1.386\n",
      "[INFO: 2054027159.py:   57]:   [D] D_total_loss: 1.386\n",
      "[INFO: 2054027159.py:   60]:   [G] G_discriminator_loss: 0.693\n",
      "[INFO: 2054027159.py:   60]:   [G] G_total_loss: 0.693\n",
      "[INFO: 2054027159.py:   55]: t = 42041 / 42093\n",
      "[INFO: 2054027159.py:   57]:   [D] D_data_loss: 1.386\n",
      "[INFO: 2054027159.py:   57]:   [D] D_total_loss: 1.386\n",
      "[INFO: 2054027159.py:   60]:   [G] G_discriminator_loss: 0.693\n",
      "[INFO: 2054027159.py:   60]:   [G] G_total_loss: 0.693\n",
      "[INFO: 2054027159.py:   55]: t = 42046 / 42093\n",
      "[INFO: 2054027159.py:   57]:   [D] D_data_loss: 1.386\n",
      "[INFO: 2054027159.py:   57]:   [D] D_total_loss: 1.386\n",
      "[INFO: 2054027159.py:   60]:   [G] G_discriminator_loss: 0.693\n",
      "[INFO: 2054027159.py:   60]:   [G] G_total_loss: 0.693\n",
      "[INFO: 2054027159.py:   55]: t = 42051 / 42093\n",
      "[INFO: 2054027159.py:   57]:   [D] D_data_loss: 1.386\n",
      "[INFO: 2054027159.py:   57]:   [D] D_total_loss: 1.386\n",
      "[INFO: 2054027159.py:   60]:   [G] G_discriminator_loss: 0.693\n",
      "[INFO: 2054027159.py:   60]:   [G] G_total_loss: 0.693\n",
      "[INFO: 2054027159.py:   55]: t = 42056 / 42093\n",
      "[INFO: 2054027159.py:   57]:   [D] D_data_loss: 1.386\n",
      "[INFO: 2054027159.py:   57]:   [D] D_total_loss: 1.386\n",
      "[INFO: 2054027159.py:   60]:   [G] G_discriminator_loss: 0.693\n",
      "[INFO: 2054027159.py:   60]:   [G] G_total_loss: 0.693\n",
      "[INFO: 2054027159.py:   55]: t = 42061 / 42093\n",
      "[INFO: 2054027159.py:   57]:   [D] D_data_loss: 1.386\n",
      "[INFO: 2054027159.py:   57]:   [D] D_total_loss: 1.386\n",
      "[INFO: 2054027159.py:   60]:   [G] G_discriminator_loss: 0.693\n",
      "[INFO: 2054027159.py:   60]:   [G] G_total_loss: 0.693\n",
      "[INFO: 2054027159.py:   55]: t = 42066 / 42093\n",
      "[INFO: 2054027159.py:   57]:   [D] D_data_loss: 1.386\n",
      "[INFO: 2054027159.py:   57]:   [D] D_total_loss: 1.386\n",
      "[INFO: 2054027159.py:   60]:   [G] G_discriminator_loss: 0.693\n",
      "[INFO: 2054027159.py:   60]:   [G] G_total_loss: 0.693\n",
      "[INFO: 2054027159.py:   55]: t = 42071 / 42093\n",
      "[INFO: 2054027159.py:   57]:   [D] D_data_loss: 1.386\n",
      "[INFO: 2054027159.py:   57]:   [D] D_total_loss: 1.386\n",
      "[INFO: 2054027159.py:   60]:   [G] G_discriminator_loss: 0.693\n",
      "[INFO: 2054027159.py:   60]:   [G] G_total_loss: 0.693\n",
      "[INFO: 2054027159.py:   55]: t = 42076 / 42093\n",
      "[INFO: 2054027159.py:   57]:   [D] D_data_loss: 1.386\n",
      "[INFO: 2054027159.py:   57]:   [D] D_total_loss: 1.386\n",
      "[INFO: 2054027159.py:   60]:   [G] G_discriminator_loss: 0.693\n",
      "[INFO: 2054027159.py:   60]:   [G] G_total_loss: 0.693\n",
      "[INFO: 2054027159.py:   55]: t = 42081 / 42093\n",
      "[INFO: 2054027159.py:   57]:   [D] D_data_loss: 1.386\n",
      "[INFO: 2054027159.py:   57]:   [D] D_total_loss: 1.386\n",
      "[INFO: 2054027159.py:   60]:   [G] G_discriminator_loss: 0.693\n",
      "[INFO: 2054027159.py:   60]:   [G] G_total_loss: 0.693\n",
      "[INFO: 2054027159.py:   55]: t = 42086 / 42093\n",
      "[INFO: 2054027159.py:   57]:   [D] D_data_loss: 1.386\n",
      "[INFO: 2054027159.py:   57]:   [D] D_total_loss: 1.386\n",
      "[INFO: 2054027159.py:   60]:   [G] G_discriminator_loss: 0.693\n",
      "[INFO: 2054027159.py:   60]:   [G] G_total_loss: 0.693\n",
      "[INFO: 2054027159.py:   55]: t = 42091 / 42093\n",
      "[INFO: 2054027159.py:   57]:   [D] D_data_loss: 1.386\n",
      "[INFO: 2054027159.py:   57]:   [D] D_total_loss: 1.386\n",
      "[INFO: 2054027159.py:   60]:   [G] G_discriminator_loss: 0.693\n",
      "[INFO: 2054027159.py:   60]:   [G] G_total_loss: 0.693\n"
     ]
    }
   ],
   "source": [
    "t0 = None\n",
    "while t < args.num_iterations: # 1000\n",
    "    gc.collect()\n",
    "    d_steps_left = args.d_steps # 2\n",
    "    g_steps_left = args.g_steps # 1\n",
    "    epoch += 1\n",
    "    logger.info('Starting epoch {}'.format(epoch))\n",
    "    for batch in train_loader: # batch\n",
    "        if args.timing == 1: # default = 0\n",
    "            torch.cuda.synchronize()\n",
    "            t1 = time.time()\n",
    "\n",
    "        # Decide whether to use the batch for stepping on discriminator or\n",
    "        # generator; an iteration consists of args.d_steps steps on the\n",
    "        # discriminator followed by args.g_steps steps on the generator.\n",
    "        \n",
    "        if d_steps_left > 0:\n",
    "            step_type = 'd'\n",
    "            losses_d = discriminator_step(args, batch, generator,\n",
    "                                            discriminator, d_loss_fn,\n",
    "                                            optimizer_d)\n",
    "            checkpoint['norm_d'].append(\n",
    "                get_total_norm(discriminator.parameters()))\n",
    "            d_steps_left -= 1\n",
    "            \n",
    "        elif g_steps_left > 0:\n",
    "            step_type = 'g'\n",
    "            losses_g = generator_step(args, batch, generator,\n",
    "                                        discriminator, g_loss_fn, # g_loss_fn = gan_g_loss\n",
    "                                        optimizer_g)\n",
    "            \n",
    "            checkpoint['norm_g'].append(\n",
    "                get_total_norm(generator.parameters())\n",
    "            )\n",
    "            g_steps_left -= 1\n",
    "\n",
    "        if args.timing == 1:\n",
    "            torch.cuda.synchronize()\n",
    "            t2 = time.time()\n",
    "            logger.info('{} step took {}'.format(step_type, t2 - t1))\n",
    "\n",
    "        # Skip the rest if we are not at the end of an iteration\n",
    "        if d_steps_left > 0 or g_steps_left > 0:\n",
    "            continue\n",
    "\n",
    "        if args.timing == 1:\n",
    "            if t0 is not None:\n",
    "                logger.info('Interation {} took {}'.format(\n",
    "                    t - 1, time.time() - t0\n",
    "                ))\n",
    "            t0 = time.time()\n",
    "\n",
    "        # Maybe save loss\n",
    "        if t % args.print_every == 0:\n",
    "            logger.info('t = {} / {}'.format(t + 1, args.num_iterations))\n",
    "            for k, v in sorted(losses_d.items()):\n",
    "                logger.info('  [D] {}: {:.3f}'.format(k, v))\n",
    "                checkpoint['D_losses'][k].append(v)\n",
    "            for k, v in sorted(losses_g.items()):\n",
    "                logger.info('  [G] {}: {:.3f}'.format(k, v))\n",
    "                checkpoint['G_losses'][k].append(v)\n",
    "            checkpoint['losses_ts'].append(t)\n",
    "\n",
    "        # Maybe save a checkpoint\n",
    "        if t > 0 and t % args.checkpoint_every == 0:\n",
    "            checkpoint['counters']['t'] = t\n",
    "            checkpoint['counters']['epoch'] = epoch\n",
    "            checkpoint['sample_ts'].append(t)\n",
    "\n",
    "            # Check stats on the validation set\n",
    "            logger.info('Checking stats on val ...')\n",
    "            metrics_val = check_accuracy(\n",
    "                args, val_loader, generator, discriminator, \n",
    "                d_loss_fn, limit=False\n",
    "            )\n",
    "            logger.info('Checking stats on train ...')\n",
    "            metrics_train = check_accuracy(\n",
    "                args, train_loader, generator, discriminator,\n",
    "                d_loss_fn, limit=True\n",
    "            )\n",
    "\n",
    "            for k, v in sorted(metrics_val.items()):\n",
    "                logger.info('  [val] {}: {:.3f}'.format(k, v))\n",
    "                checkpoint['metrics_val'][k].append(v)\n",
    "                \n",
    "            for k, v in sorted(metrics_train.items()):\n",
    "                logger.info('  [train] {}: {:.3f}'.format(k, v))\n",
    "                checkpoint['metrics_train'][k].append(v)\n",
    "\n",
    "            min_ade = min(checkpoint['metrics_val']['ade'])\n",
    "            min_ade_nl = min(checkpoint['metrics_val']['ade_nl'])\n",
    "\n",
    "            if metrics_val['ade'] == min_ade:\n",
    "                logger.info('New low for avg_disp_error')\n",
    "                checkpoint['best_t'] = t\n",
    "                checkpoint['g_best_state'] = generator.state_dict()\n",
    "                checkpoint['d_best_state'] = discriminator.state_dict()\n",
    "\n",
    "            if metrics_val['ade_nl'] == min_ade_nl:\n",
    "                logger.info('New low for avg_disp_error_nl')\n",
    "                checkpoint['best_t_nl'] = t\n",
    "                checkpoint['g_best_nl_state'] = generator.state_dict()\n",
    "                checkpoint['d_best_nl_state'] = discriminator.state_dict()\n",
    "\n",
    "            # Save another checkpoint with model weights and\n",
    "            # optimizer state\n",
    "            checkpoint['g_state'] = generator.state_dict()\n",
    "            checkpoint['g_optim_state'] = optimizer_g.state_dict()\n",
    "            checkpoint['d_state'] = discriminator.state_dict()\n",
    "            checkpoint['d_optim_state'] = optimizer_d.state_dict()\n",
    "            \n",
    "            checkpoint_path = os.path.join(\n",
    "                args.output_dir, '%s_with_model.pt' % args.checkpoint_name\n",
    "            )\n",
    "            \n",
    "            logger.info('Saving checkpoint to {}'.format(checkpoint_path))\n",
    "            torch.save(checkpoint, checkpoint_path)\n",
    "            logger.info('Done.')\n",
    "\n",
    "            # Save a checkpoint with no model weights by making a shallow\n",
    "            # copy of the checkpoint excluding some items\n",
    "            \n",
    "            checkpoint_path = os.path.join(\n",
    "                args.output_dir, '%s_no_model.pt' % args.checkpoint_name)\n",
    "            \n",
    "            logger.info('Saving checkpoint to {}'.format(checkpoint_path))\n",
    "            \n",
    "            key_blacklist = [\n",
    "                'g_state', 'd_state', 'g_best_state', 'g_best_nl_state',\n",
    "                'g_optim_state', 'd_optim_state', 'd_best_state',\n",
    "                'd_best_nl_state'\n",
    "            ]\n",
    "            \n",
    "            small_checkpoint = {}\n",
    "            for k, v in checkpoint.items():\n",
    "                if k not in key_blacklist:\n",
    "                    small_checkpoint[k] = v\n",
    "            torch.save(small_checkpoint, checkpoint_path)\n",
    "            logger.info('Done.')\n",
    "\n",
    "        t += 1\n",
    "        d_steps_left = args.d_steps\n",
    "        g_steps_left = args.g_steps\n",
    "        if t >= args.num_iterations:\n",
    "            break\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_step(\n",
    "    args, batch, generator, discriminator, d_loss_fn, optimizer_d\n",
    "):\n",
    "    batch = [tensor.cuda() for tensor in batch]\n",
    "    \n",
    "    (obs_traj, obs_state, _,\n",
    "     pred_traj_gt, _, _,\n",
    "     obs_traj_rel, pred_traj_gt_rel, \n",
    "     _, loss_mask, seq_start_end \n",
    "     ) = batch\n",
    "    \n",
    "    losses = {}\n",
    "    loss = torch.zeros(1).to(pred_traj_gt)\n",
    "\n",
    "    generator_out = generator(obs_traj, obs_traj_rel, seq_start_end,\n",
    "                                obs_state   # add\n",
    "                                )\n",
    "    pred_traj_fake_rel = generator_out\n",
    "    pred_traj_fake = relative_to_abs(pred_traj_fake_rel, obs_traj[-1])\n",
    "\n",
    "    traj_real = torch.cat([obs_traj, pred_traj_gt], dim=0) # Sizes of tensors must match except in dimension 0. Expected size 2 but got size 4 for tensor number 1 in the list.\n",
    "    traj_real_rel = torch.cat([obs_traj_rel, pred_traj_gt_rel], dim=0)\n",
    "    traj_fake = torch.cat([obs_traj, pred_traj_fake], dim=0)\n",
    "    traj_fake_rel = torch.cat([obs_traj_rel, pred_traj_fake_rel], dim=0)\n",
    "\n",
    "    scores_fake = discriminator(traj_fake, traj_fake_rel, seq_start_end)\n",
    "    scores_real = discriminator(traj_real, traj_real_rel, seq_start_end)\n",
    "\n",
    "    # Compute loss with optional gradient penalty\n",
    "    data_loss = d_loss_fn(scores_real, scores_fake)\n",
    "    losses['D_data_loss'] = data_loss.item()\n",
    "    loss += data_loss\n",
    "    losses['D_total_loss'] = loss.item()\n",
    "\n",
    "    optimizer_d.zero_grad()\n",
    "    loss.backward()\n",
    "    if args.clipping_threshold_d > 0:\n",
    "        nn.utils.clip_grad_norm_(discriminator.parameters(),\n",
    "                                 args.clipping_threshold_d)\n",
    "    optimizer_d.step()\n",
    "\n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_step(\n",
    "    args, batch, generator, discriminator, g_loss_fn, optimizer_g\n",
    "):\n",
    "    batch = [tensor.cuda() for tensor in batch]\n",
    "    \n",
    "    (obs_traj, obs_state, _,\n",
    "     \n",
    "     pred_traj_gt, _, _,\n",
    "     \n",
    "     obs_traj_rel, pred_traj_gt_rel, \n",
    "     \n",
    "     _, loss_mask, seq_start_end \n",
    "     ) = batch\n",
    "    \n",
    "    losses = {}\n",
    "    loss = torch.zeros(1).to(pred_traj_gt)\n",
    "    g_l2_loss_rel = []\n",
    "\n",
    "    loss_mask = loss_mask[:, args.obs_len:]\n",
    "\n",
    "    for _ in range(args.best_k):\n",
    "        generator_out = generator(obs_traj, obs_traj_rel, seq_start_end,\n",
    "                                obs_state # add\n",
    "                                  )\n",
    "\n",
    "        pred_traj_fake_rel = generator_out\n",
    "        pred_traj_fake = relative_to_abs(pred_traj_fake_rel, obs_traj[-1])\n",
    "\n",
    "        if args.l2_loss_weight > 0:\n",
    "            g_l2_loss_rel.append(args.l2_loss_weight * l2_loss(\n",
    "                pred_traj_fake_rel,\n",
    "                pred_traj_gt_rel,\n",
    "                loss_mask,\n",
    "                mode='raw'))\n",
    "\n",
    "    g_l2_loss_sum_rel = torch.zeros(1).to(pred_traj_gt)\n",
    "    if args.l2_loss_weight > 0:\n",
    "        g_l2_loss_rel = torch.stack(g_l2_loss_rel, dim=1)\n",
    "        for start, end in seq_start_end.data:\n",
    "            _g_l2_loss_rel = g_l2_loss_rel[start:end]\n",
    "            _g_l2_loss_rel = torch.sum(_g_l2_loss_rel, dim=0)\n",
    "            _g_l2_loss_rel = torch.min(_g_l2_loss_rel) / torch.sum(\n",
    "                loss_mask[start:end])\n",
    "            g_l2_loss_sum_rel += _g_l2_loss_rel\n",
    "        losses['G_l2_loss_rel'] = g_l2_loss_sum_rel.item()\n",
    "        loss += g_l2_loss_sum_rel\n",
    "\n",
    "    traj_fake = torch.cat([obs_traj, pred_traj_fake], dim=0)\n",
    "    traj_fake_rel = torch.cat([obs_traj_rel, pred_traj_fake_rel], dim=0)\n",
    "\n",
    "    scores_fake = discriminator(traj_fake, traj_fake_rel, seq_start_end)\n",
    "    discriminator_loss = g_loss_fn(scores_fake)\n",
    "\n",
    "    loss += discriminator_loss\n",
    "    losses['G_discriminator_loss'] = discriminator_loss.item()\n",
    "    losses['G_total_loss'] = loss.item()\n",
    "\n",
    "    optimizer_g.zero_grad()\n",
    "    loss.backward()\n",
    "    if args.clipping_threshold_g > 0:\n",
    "        nn.utils.clip_grad_norm_(\n",
    "            generator.parameters(), args.clipping_threshold_g\n",
    "        )\n",
    "    optimizer_g.step()\n",
    "\n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(\n",
    "    args, loader, generator, discriminator, d_loss_fn, limit=False\n",
    "):\n",
    "    d_losses = []\n",
    "    metrics = {}\n",
    "    g_l2_losses_abs, g_l2_losses_rel = ([],) * 2\n",
    "    disp_error, disp_error_l, disp_error_nl = ([],) * 3\n",
    "    f_disp_error, f_disp_error_l, f_disp_error_nl = ([],) * 3\n",
    "    total_traj, total_traj_l, total_traj_nl = 0, 0, 0\n",
    "    loss_mask_sum = 0\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:    \n",
    "            batch = [tensor.cuda() for tensor in batch]\n",
    "\n",
    "            (obs_traj, obs_state, _,     \n",
    "            pred_traj_gt, _, _,\n",
    "            obs_traj_rel, pred_traj_gt_rel, \n",
    "            non_linear_ped, loss_mask, seq_start_end \n",
    "            ) = batch                                   # check_accuracy를 위해, batch에서 non_linear_ped도 불러와야 함\n",
    "            \n",
    "            linear_ped = 1 - non_linear_ped\n",
    "            loss_mask = loss_mask[:, args.obs_len:]\n",
    "\n",
    "            pred_traj_fake_rel = generator(\n",
    "                obs_traj, obs_traj_rel, seq_start_end,\n",
    "                obs_state\n",
    "            )\n",
    "            pred_traj_fake = relative_to_abs(pred_traj_fake_rel, obs_traj[-1])\n",
    "\n",
    "            g_l2_loss_abs, g_l2_loss_rel = cal_l2_losses(\n",
    "                pred_traj_gt, pred_traj_gt_rel, pred_traj_fake,\n",
    "                pred_traj_fake_rel, loss_mask\n",
    "            )\n",
    "            ade, ade_l, ade_nl = cal_ade(\n",
    "                pred_traj_gt, pred_traj_fake, linear_ped, non_linear_ped\n",
    "            )\n",
    "\n",
    "            fde, fde_l, fde_nl = cal_fde(\n",
    "                pred_traj_gt, pred_traj_fake, linear_ped, non_linear_ped\n",
    "            )\n",
    "\n",
    "            traj_real = torch.cat([obs_traj, pred_traj_gt], dim=0)\n",
    "            traj_real_rel = torch.cat([obs_traj_rel, pred_traj_gt_rel], dim=0)\n",
    "            traj_fake = torch.cat([obs_traj, pred_traj_fake], dim=0)\n",
    "            traj_fake_rel = torch.cat([obs_traj_rel, pred_traj_fake_rel], dim=0)\n",
    "\n",
    "            scores_fake = discriminator(traj_fake, traj_fake_rel, seq_start_end)\n",
    "            scores_real = discriminator(traj_real, traj_real_rel, seq_start_end)\n",
    "\n",
    "            d_loss = d_loss_fn(scores_real, scores_fake)\n",
    "            d_losses.append(d_loss.item())\n",
    "\n",
    "            g_l2_losses_abs.append(g_l2_loss_abs.item())\n",
    "            g_l2_losses_rel.append(g_l2_loss_rel.item())\n",
    "            disp_error.append(ade.item())\n",
    "            disp_error_l.append(ade_l.item())\n",
    "            disp_error_nl.append(ade_nl.item())\n",
    "            f_disp_error.append(fde.item())\n",
    "            f_disp_error_l.append(fde_l.item())\n",
    "            f_disp_error_nl.append(fde_nl.item())\n",
    "\n",
    "            loss_mask_sum += torch.numel(loss_mask.data)\n",
    "            total_traj += pred_traj_gt.size(1)\n",
    "            total_traj_l += torch.sum(linear_ped).item()\n",
    "            total_traj_nl += torch.sum(non_linear_ped).item()\n",
    "            if limit and total_traj >= args.num_samples_check:\n",
    "                break\n",
    "\n",
    "    metrics['d_loss'] = sum(d_losses) / len(d_losses)\n",
    "    metrics['g_l2_loss_abs'] = sum(g_l2_losses_abs) / loss_mask_sum\n",
    "    metrics['g_l2_loss_rel'] = sum(g_l2_losses_rel) / loss_mask_sum\n",
    "\n",
    "    metrics['ade'] = sum(disp_error) / (total_traj * args.pred_len)\n",
    "    metrics['fde'] = sum(f_disp_error) / total_traj\n",
    "    if total_traj_l != 0:\n",
    "        metrics['ade_l'] = sum(disp_error_l) / (total_traj_l * args.pred_len)\n",
    "        metrics['fde_l'] = sum(f_disp_error_l) / total_traj_l\n",
    "    else:\n",
    "        metrics['ade_l'] = 0\n",
    "        metrics['fde_l'] = 0\n",
    "    if total_traj_nl != 0:\n",
    "        metrics['ade_nl'] = sum(disp_error_nl) / (\n",
    "            total_traj_nl * args.pred_len)\n",
    "        metrics['fde_nl'] = sum(f_disp_error_nl) / total_traj_nl\n",
    "    else:\n",
    "        metrics['ade_nl'] = 0\n",
    "        metrics['fde_nl'] = 0\n",
    "\n",
    "    generator.train()\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def cal_l2_losses(\n",
    "    pred_traj_gt, pred_traj_gt_rel, pred_traj_fake, pred_traj_fake_rel,\n",
    "    loss_mask\n",
    "):\n",
    "    g_l2_loss_abs = l2_loss(\n",
    "        pred_traj_fake, pred_traj_gt, loss_mask, mode='sum'\n",
    "    )\n",
    "    g_l2_loss_rel = l2_loss(\n",
    "        pred_traj_fake_rel, pred_traj_gt_rel, loss_mask, mode='sum'\n",
    "    )\n",
    "    return g_l2_loss_abs, g_l2_loss_rel\n",
    "\n",
    "\n",
    "def cal_ade(pred_traj_gt, pred_traj_fake, linear_ped, non_linear_ped):\n",
    "    ade = displacement_error(pred_traj_fake, pred_traj_gt)\n",
    "    ade_l = displacement_error(pred_traj_fake, pred_traj_gt, linear_ped)\n",
    "    ade_nl = displacement_error(pred_traj_fake, pred_traj_gt, non_linear_ped)\n",
    "    return ade, ade_l, ade_nl\n",
    "\n",
    "\n",
    "def cal_fde(\n",
    "    pred_traj_gt, pred_traj_fake, linear_ped, non_linear_ped\n",
    "):\n",
    "    fde = final_displacement_error(pred_traj_fake[-1], pred_traj_gt[-1])\n",
    "    fde_l = final_displacement_error(\n",
    "        pred_traj_fake[-1], pred_traj_gt[-1], linear_ped\n",
    "    )\n",
    "    fde_nl = final_displacement_error(\n",
    "        pred_traj_fake[-1], pred_traj_gt[-1], non_linear_ped\n",
    "    )\n",
    "    return fde, fde_l, fde_nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "waterloo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
