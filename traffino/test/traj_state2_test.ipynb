{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(_path, delim='\\t'):\n",
    "    data = []\n",
    "    if delim == 'tab':\n",
    "        delim = '\\t'\n",
    "    elif delim == 'space':\n",
    "        delim = ' '\n",
    "    with open(_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split(delim)\n",
    "            line = [float(i) for i in line]\n",
    "            data.append(line)\n",
    "    return np.asarray(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_fit(traj, traj_len, \n",
    "             threshold\n",
    "             ):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    - traj: Numpy array of shape (2, traj_len)\n",
    "    - traj_len: Len of trajectory\n",
    "    - threshold: Minimum error to be considered for non linear traj\n",
    "    Output:\n",
    "    - int: 1 -> Non Linear 0-> Linear\n",
    "    \"\"\"\n",
    "    t = np.linspace(0, traj_len - 1, traj_len) # np.linspace(시작점, 끝점, 구간 내 숫자 개수)\n",
    "    res_x = np.polyfit(t, traj[0, -traj_len:], 2, full=True)[1]\n",
    "    res_y = np.polyfit(t, traj[1, -traj_len:], 2, full=True)[1]\n",
    "    if res_x + res_y >= threshold: # error\n",
    "       return 1.0\n",
    "    else:\n",
    "       return 0.0\n",
    "    return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16387\n",
      "16387\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import os\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "path = 'C:\\\\Users\\\\NGN\\\\dev\\\\Traffino\\\\TRAFFINO\\\\traffino\\\\datasets\\\\waterloo\\\\train\\\\0769_prep.txt'\n",
    "path2 = 'C:\\\\Users\\\\NGN\\\\dev\\\\Traffino\\\\TRAFFINO\\\\traffino\\\\datasets\\\\waterloo\\\\train\\\\0769_prep2.txt'\n",
    "path3 = 'C:\\\\Users\\\\NGN\\\\dev\\\\Traffino\\\\TRAFFINO\\\\traffino\\\\datasets\\\\waterloo\\\\train\\\\0769_prep3.txt'\n",
    "delim = '\\t'\n",
    "data = read_file(path, delim)\n",
    "data2 = read_file(path2, delim)\n",
    "data3 = read_file(path3, delim)\n",
    "print(len(data))\n",
    "\n",
    "print(len(data))\n",
    "print(type(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "727\n"
     ]
    }
   ],
   "source": [
    "frames = np.unique(data[:, 0]).tolist()\n",
    "# print(frames[0])\n",
    "print(len(frames))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame_data_all = []\n",
    "frame_data = []\n",
    "state_data = []\n",
    "traffic_data = []\n",
    "# data를 frame 단위로 변환\n",
    "for frame in frames:\n",
    "    frame_data_all.append(data[frame == data[:, 0], :4])  # all\n",
    "    frame_data.append(data[frame == data[:, 0], :4]) # 전체 frame에(7994개 scene) 대해, 각 frame별 frame_data (agent 정보, x, y) --> 2차원 list\n",
    "    state_data.append(data2[frame == data2[:, 0], :])\n",
    "    traffic_data.append(data3[frame == data3[:, 0], ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(frame_data))\n",
    "print(type(frame_data))\n",
    "# print(frame_data)\n",
    "# print(len(frame_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(state_data))\n",
    "print(type(state_data))\n",
    "# print(state_data)\n",
    "# print(len(state_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(traffic_data))\n",
    "print(type(traffic_data))\n",
    "# print(traffic_data)\n",
    "# print(len(state_data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(frame_data[0:20])\n",
    "# print(len(frame_data[0:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len=20\n",
    "skip=1\n",
    "\n",
    "num_sequences = int(math.ceil((len(frames) - seq_len + 1) / skip)) # seqence 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs_len = 8\n",
    "pred_len = 12\n",
    "threshold = 0.002\n",
    "min_agent =1 \n",
    "num_agents_in_seq = []\n",
    "seq_list = []\n",
    "seq_list2 = [] # state\n",
    "seq_list3 = [] # traffic \n",
    "\n",
    "non_linear_agent = []\n",
    "loss_mask_list = []\n",
    "seq_list_rel = []\n",
    "seq_list_rel2 = [] # state\n",
    "seq_list_rel3 = [] # traffic \n",
    "\n",
    "\n",
    "\n",
    "for idx in range(0, num_sequences * skip + 1, skip):\n",
    "    curr_seq_data = np.concatenate(                         # num_sequnce만큼 끊어서 curr seq_data 생성\n",
    "        frame_data[idx:idx + seq_len], axis=0               # ex) seq 1: 1-20 frame, seq 2: 2-21 frame ... \n",
    "    )\n",
    "    curr_seq_data2 = np.concatenate(                         # num_sequnce만큼 끊어서 curr seq_data 생성\n",
    "        state_data[idx:idx + seq_len], axis=0               # ex) seq 1: 1-20 frame, seq 2: 2-21 frame ... \n",
    "    )\n",
    "    curr_seq_data3 = np.concatenate(                         # num_sequnce만큼 끊어서 curr seq_data 생성\n",
    "        traffic_data[idx:idx + seq_len], axis=0               # ex) seq 1: 1-20 frame, seq 2: 2-21 frame ... \n",
    "    )\n",
    "    # print(idx) # 7976 (sequnece 개수)\n",
    "    # print(curr_seq_data)\n",
    "    # print(len(curr_seq_data)) # 현재 시퀀스에 있는 row (프레임 별 agent)의 합 --> 20개 프레임에 대한 agent (중복 포함) 합 --> 20*20= 400\n",
    "\n",
    "    agents_in_curr_seq = np.unique(curr_seq_data[:, 1])       # 현재 seq에 있는 agents 목록, 모든 행의 1번째(agent 정보) 열 slicing\n",
    "\n",
    "    # print(len(agents_in_curr_seq))\n",
    "    # print(agents_in_curr_seq)\n",
    "    curr_seq_rel = np.zeros((len(agents_in_curr_seq), 2,        # (현재 seq에 있는 agents 개수, 2, seq_len) \n",
    "                                seq_len))\n",
    "    curr_seq_rel2 = np.zeros((len(agents_in_curr_seq), 4,        # (현재 seq에 있는 agents 개수, 4, seq_len) --> state 저장용\n",
    "                            seq_len))\n",
    "    curr_seq_rel3 = np.zeros((len(agents_in_curr_seq), 1,        # (현재 seq에 있는 agents 개수, 1, seq_len) --> traffic light 저장용\n",
    "                        seq_len))\n",
    "    \n",
    "    # print(curr_seq_rel)\n",
    "    curr_seq = np.zeros((len(agents_in_curr_seq), 2, seq_len))   # (현재 seq에 있는 agents 개수, 2, seq_len) \n",
    "    curr_seq2 = np.zeros((len(agents_in_curr_seq), 4, seq_len))   # (현재 seq에 있는 agents 개수, 4, seq_len) --> state 저장용\n",
    "    curr_seq3 = np.zeros((len(agents_in_curr_seq), 1, seq_len))   # (현재 seq에 있는 agents 개수, 3, seq_len) --> traffic light 저장용\n",
    "    \n",
    "    curr_loss_mask = np.zeros((len(agents_in_curr_seq),\n",
    "                                seq_len))\n",
    "    num_agents_considered = 0\n",
    "    _non_linear_agent = []\n",
    "    \n",
    "    for _, agent_id in enumerate(agents_in_curr_seq):           # 현재 seq에 있는 agents 목록\n",
    "        curr_agent_seq = curr_seq_data[ curr_seq_data[:, 1] == # 현재 seq에 있는 agent의 위치 seqeunce curr_agent_seq: (20, 4)\n",
    "                                        agent_id, :]\n",
    "        curr_agent_seq2 = curr_seq_data2[ curr_seq_data2[:, 1] == # 현재 seq에 있는 agent의 상태 seqeunce curr_agent_seq: (20, 4)\n",
    "                                agent_id, :]\n",
    "        curr_agent_seq3 = curr_seq_data3[ curr_seq_data3[:, 1] == # 현재 seq에 있는 agent의 traffic seqeunce curr_agent_seq: (20, 4)\n",
    "                                agent_id, :]\n",
    "        # print(curr_agent_seq)\n",
    "        # print(agent_id)\n",
    "        curr_agent_seq = np.around(curr_agent_seq, decimals=4)\n",
    "        curr_agent_seq2 = np.around(curr_agent_seq2, decimals=4)\n",
    "        curr_agent_seq3 = np.around(curr_agent_seq3, decimals=4)\n",
    "                \n",
    "        pad_front = frames.index(curr_agent_seq[0, 0]) - idx\n",
    "        pad_end = frames.index(curr_agent_seq[-1, 0]) - idx + 1\n",
    "        if pad_end - pad_front != seq_len:\n",
    "            continue\n",
    "        curr_agent_seq = np.transpose(curr_agent_seq[:, 2:])\n",
    "        curr_agent_seq2 = np.transpose(curr_agent_seq2[:, 2:])\n",
    "        curr_agent_seq3 = np.transpose(curr_agent_seq3[:, 2:])\n",
    "        \n",
    "        curr_agent_seq = curr_agent_seq\n",
    "        # Make coordinates relative\n",
    "        rel_curr_agent_seq = np.zeros(curr_agent_seq.shape)\n",
    "        \n",
    "        rel_curr_agent_seq[:, 1:] = \\\n",
    "            curr_agent_seq[:, 1:] - curr_agent_seq[:, :-1]\n",
    "        _idx = num_agents_considered\n",
    "        \n",
    "        curr_seq[_idx, :, pad_front:pad_end] = curr_agent_seq\n",
    "        curr_seq2[_idx, :, pad_front:pad_end] = curr_agent_seq2\n",
    "        curr_seq3[_idx, :, pad_front:pad_end] = curr_agent_seq3\n",
    "        \n",
    "        curr_seq_rel[_idx, :, pad_front:pad_end] = rel_curr_agent_seq\n",
    "        # Linear vs Non-Linear Trajectory\n",
    "        _non_linear_agent.append(\n",
    "            poly_fit(curr_agent_seq, pred_len \n",
    "                        ,threshold\n",
    "                        )\n",
    "                        )\n",
    "        curr_loss_mask[_idx, pad_front:pad_end] = 1\n",
    "        num_agents_considered += 1\n",
    "        \n",
    "    if num_agents_considered > min_agent:\n",
    "        non_linear_agent += _non_linear_agent\n",
    "        num_agents_in_seq.append(num_agents_considered)\n",
    "        loss_mask_list.append(curr_loss_mask[:num_agents_considered])\n",
    "        seq_list.append(curr_seq[:num_agents_considered])\n",
    "        seq_list2.append(curr_seq2[:num_agents_considered])\n",
    "        seq_list3.append(curr_seq3[:num_agents_considered])\n",
    "        \n",
    "        seq_list_rel.append(curr_seq_rel[:num_agents_considered])\n",
    "        seq_list_rel2.append(curr_seq_rel2[:num_agents_considered])\n",
    "        seq_list_rel3.append(curr_seq_rel3[:num_agents_considered])\n",
    "\n",
    "num_seq = len(seq_list)\n",
    "        \n",
    "seq_list = np.concatenate(seq_list, axis=0)\n",
    "seq_list2 = np.concatenate(seq_list2, axis=0)\n",
    "seq_list3 = np.concatenate(seq_list3, axis=0)\n",
    "seq_list_rel = np.concatenate(seq_list_rel, axis=0)\n",
    "seq_list_rel2 = np.concatenate(seq_list_rel2, axis=0)\n",
    "seq_list_rel3 = np.concatenate(seq_list_rel3, axis=0)\n",
    "\n",
    "loss_mask_list = np.concatenate(loss_mask_list, axis=0)\n",
    "non_linear_agent = np.asarray(non_linear_agent)\n",
    "\n",
    "# Convert numpy -> Torch Tensor\n",
    "obs_traj = torch.from_numpy(\n",
    "    seq_list[:, :, :obs_len]).type(torch.float)\n",
    "obs_state = torch.from_numpy(\n",
    "    seq_list2[:, :, :obs_len]).type(torch.float)\n",
    "# obs_traffic = torch.from_numpy(\n",
    "#     seq_list3[:, :, :obs_len]).type(torch.float)\n",
    "\n",
    "pred_traj = torch.from_numpy(\n",
    "    seq_list[:, :, obs_len:]).type(torch.float)\n",
    "pred_state = torch.from_numpy(\n",
    "    seq_list2[:, :, obs_len:]).type(torch.float)\n",
    "# pred_traffic = torch.from_numpy(\n",
    "#     seq_list3[:, :, obs_len:]).type(torch.float)\n",
    "\n",
    "obs_traj_rel = torch.from_numpy(\n",
    "    seq_list_rel[:, :, :obs_len]).type(torch.float)\n",
    "obs_state_rel = torch.from_numpy(\n",
    "    seq_list_rel2[:, :, :obs_len]).type(torch.float)\n",
    "# obs_traffic_rel = torch.from_numpy(\n",
    "#     seq_list_rel3[:, :, :obs_len]).type(torch.float)\n",
    "\n",
    "pred_traj_rel = torch.from_numpy(\n",
    "    seq_list_rel[:, :, obs_len:]).type(torch.float)\n",
    "pred_state_rel = torch.from_numpy(\n",
    "    seq_list_rel2[:, :, obs_len:]).type(torch.float)\n",
    "# pred_traffic_rel = torch.from_numpy(\n",
    "#     seq_list_rel3[:, :, obs_len:]).type(torch.float)\n",
    "\n",
    "loss_mask = torch.from_numpy(loss_mask_list).type(torch.float)\n",
    "non_linear_agent = torch.from_numpy(non_linear_agent).type(torch.float)\n",
    "cum_start_idx = [0] + np.cumsum(num_agents_in_seq).tolist()\n",
    "seq_start_end = [\n",
    "    (start, end)\n",
    "    for start, end in zip(cum_start_idx, cum_start_idx[1:])\n",
    "]\n",
    "\n",
    "def len():              # len(train_dset)\n",
    "    return num_seq\n",
    "\n",
    "def getitem(index):\n",
    "    start, end = seq_start_end[index]\n",
    "    out = [\n",
    "        obs_traj[start:end, :], \n",
    "        obs_state[start:end, :],\n",
    "        pred_traj[start:end, :],\n",
    "        pred_state[start:end, :],\n",
    "        obs_traj_rel[start:end, :], \n",
    "        obs_state_rel[start:end, :], \n",
    "        pred_traj_rel[start:end, :],\n",
    "        pred_state_rel[start:end, :],\n",
    "        non_linear_agent[start:end], \n",
    "        loss_mask[start:end, :]\n",
    "    ]\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffino",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
