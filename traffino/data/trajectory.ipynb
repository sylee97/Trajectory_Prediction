{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "191e307c-5ea1-4145-88e7-e88685d094f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23ae6897-ed13-4778-989b-c9893dd658fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cee82aac-fadf-4b4a-a54a-adb15c04af26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seq_collate(data):\n",
    "    (obs_seq_list, pred_seq_list, obs_seq_rel_list, pred_seq_rel_list,\n",
    "     non_linear_ped_list, loss_mask_list) = zip(*data)\n",
    "\n",
    "    _len = [len(seq) for seq in obs_seq_list]\n",
    "    cum_start_idx = [0] + np.cumsum(_len).tolist()\n",
    "    seq_start_end = [[start, end]\n",
    "                     for start, end in zip(cum_start_idx, cum_start_idx[1:])]\n",
    "\n",
    "    # Data format: batch, input_size, seq_len\n",
    "    # LSTM input format: seq_len, batch, input_size\n",
    "    obs_traj = torch.cat(obs_seq_list, dim=0).permute(2, 0, 1) # permute : 인덱스들을 바꾸고자 하는 위치로 변경\n",
    "    pred_traj = torch.cat(pred_seq_list, dim=0).permute(2, 0, 1)\n",
    "    obs_traj_rel = torch.cat(obs_seq_rel_list, dim=0).permute(2, 0, 1)\n",
    "    pred_traj_rel = torch.cat(pred_seq_rel_list, dim=0).permute(2, 0, 1)\n",
    "    non_linear_ped = torch.cat(non_linear_ped_list)\n",
    "    loss_mask = torch.cat(loss_mask_list, dim=0)\n",
    "    seq_start_end = torch.LongTensor(seq_start_end)\n",
    "    \n",
    "    out = [\n",
    "        obs_traj, pred_traj, obs_traj_rel, pred_traj_rel, non_linear_ped,\n",
    "        loss_mask, seq_start_end\n",
    "    ]\n",
    "\n",
    "    return tuple(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3776ecee-b8a0-4d00-84c7-c5c3eea20937",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(_path, delim='\\t'):\n",
    "    data = []\n",
    "    if delim == 'tab':\n",
    "        delim = '\\t'\n",
    "    elif delim == 'space':\n",
    "        delim = ' '\n",
    "    with open(_path, 'r') as f:\n",
    "        for line in f:\n",
    "            line = line.strip().split(delim)\n",
    "            line = [float(i) for i in line]\n",
    "            data.append(line)\n",
    "    return np.asarray(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f0ced94-e569-4fc7-914d-479bdcc23f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def poly_fit(traj, traj_len, \n",
    "             threshold\n",
    "             ):\n",
    "    \"\"\"\n",
    "    Input:\n",
    "    - traj: Numpy array of shape (2, traj_len)\n",
    "    - traj_len: Len of trajectory\n",
    "    - threshold: Minimum error to be considered for non linear traj\n",
    "    Output:\n",
    "    - int: 1 -> Non Linear 0-> Linear\n",
    "    \"\"\"\n",
    "    t = np.linspace(0, traj_len - 1, traj_len) # np.linspace(시작점, 끝점, 구간 내 숫자 개수)\n",
    "    res_x = np.polyfit(t, traj[0, -traj_len:], 2, full=True)[1]\n",
    "    res_y = np.polyfit(t, traj[1, -traj_len:], 2, full=True)[1]\n",
    "    if res_x + res_y >= threshold: # error\n",
    "       return 1.0\n",
    "    else:\n",
    "       return 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d25e2f0e-68d9-49dd-a991-c5ce2c9d152a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrajectoryDataset(Dataset):\n",
    "    \"\"\"Dataloder for the Trajectory datasets\"\"\"\n",
    "    def __init__(\n",
    "        self, data_dir, obs_len=8, pred_len=12, skip=1, \n",
    "        threshold=0.002, min_ped=1, \n",
    "        delim='\\t'\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "        - data_dir: Directory containing dataset files in the format\n",
    "        <frame_id> <agent_id> <x> <y>\n",
    "        - obs_len: Number of time-steps in input trajectories\n",
    "        - pred_len: Number of time-steps in output trajectories\n",
    "        - skip: Number of frames to skip while making the dataset\n",
    "        - threshold: Minimum error to be considered for non linear traj\n",
    "        when using a linear predictor\n",
    "        - min_ped: Minimum number of pedestrians that should be in a seqeunce\n",
    "        - delim: Delimiter in the dataset files\n",
    "        \"\"\"\n",
    "        super(TrajectoryDataset, self).__init__()\n",
    "\n",
    "        # self.data_dir = data_dir\n",
    "        self.data_dir = data_dir\n",
    "        self.obs_len = obs_len\n",
    "        self.pred_len = pred_len\n",
    "        self.skip = skip\n",
    "        self.seq_len = self.obs_len + self.pred_len\n",
    "        self.delim = delim\n",
    "\n",
    "        all_files = os.listdir(self.data_dir)\n",
    "        # print(all_files) : data_dir에 있는 파일 목록 출력\n",
    "        all_files = [os.path.join(self.data_dir, _path) for _path in all_files]\n",
    "        \n",
    "        num_peds_in_seq = []\n",
    "        seq_list = []\n",
    "        seq_list_rel = []\n",
    "        loss_mask_list = []\n",
    "        non_linear_ped = []\n",
    "        \n",
    "        for path in all_files:\n",
    "            data = read_file(path, delim)\n",
    "            frames = np.unique(data[:, 0]).tolist() # frame 번호\n",
    "            frame_data = []\n",
    "            for frame in frames:\n",
    "                frame_data.append(data[frame == data[:, 0], :]) # frame_data, 각 frame별 frame_data (agent 정보, x, y) --> 2차원 list\n",
    "            num_sequences = int(\n",
    "                math.ceil((len(frames) - self.seq_len + 1) / skip))\n",
    "\n",
    "            for idx in range(0, num_sequences * self.skip + 1, skip):\n",
    "                curr_seq_data = np.concatenate(\n",
    "                    frame_data[idx:idx + self.seq_len], axis=0) # seq_len에 해당하는 frame_data를 합침\n",
    "                peds_in_curr_seq = np.unique(curr_seq_data[:, 1]) # 현재 seq에 있는 agent 목록\n",
    "                curr_seq_rel = np.zeros((len(peds_in_curr_seq), 2, # (현재 seq에 있는 agent 수, 2, seq_len) -> seq에 있는 agent들의 seq_len 동안의 좌표\n",
    "                                         self.seq_len))\n",
    "                curr_seq = np.zeros((len(peds_in_curr_seq), 2, self.seq_len)) # (현재 seq에 있는 agent 수, 2, seq_len)\n",
    "                curr_loss_mask = np.zeros((len(peds_in_curr_seq), # (현재 seq에 있는 agent 수, seq_len)\n",
    "                                           self.seq_len))\n",
    "                num_peds_considered = 0\n",
    "                _non_linear_ped = []\n",
    "                for _, ped_id in enumerate(peds_in_curr_seq):\n",
    "                    curr_ped_seq = curr_seq_data[curr_seq_data[:, 1] ==\n",
    "                                                 ped_id, :]\n",
    "                    curr_ped_seq = np.around(curr_ped_seq, decimals=4)\n",
    "                    pad_front = frames.index(curr_ped_seq[0, 0]) - idx\n",
    "                    pad_end = frames.index(curr_ped_seq[-1, 0]) - idx + 1\n",
    "                    if pad_end - pad_front != self.seq_len:\n",
    "                        continue\n",
    "                    curr_ped_seq = np.transpose(curr_ped_seq[:, 2:])\n",
    "                    curr_ped_seq = curr_ped_seq\n",
    "                    # Make coordinates relative\n",
    "                    rel_curr_ped_seq = np.zeros(curr_ped_seq.shape)\n",
    "                    rel_curr_ped_seq[:, 1:] = \\\n",
    "                        curr_ped_seq[:, 1:] - curr_ped_seq[:, :-1]\n",
    "                    _idx = num_peds_considered\n",
    "                    curr_seq[_idx, :, pad_front:pad_end] = curr_ped_seq\n",
    "                    curr_seq_rel[_idx, :, pad_front:pad_end] = rel_curr_ped_seq\n",
    "                    # Linear vs Non-Linear Trajectory\n",
    "                    _non_linear_ped.append(\n",
    "                        poly_fit(curr_ped_seq, pred_len, threshold))\n",
    "                    curr_loss_mask[_idx, pad_front:pad_end] = 1\n",
    "                    num_peds_considered += 1\n",
    "\n",
    "                if num_peds_considered > min_ped:\n",
    "                    non_linear_ped += _non_linear_ped\n",
    "                    num_peds_in_seq.append(num_peds_considered)\n",
    "                    loss_mask_list.append(curr_loss_mask[:num_peds_considered])\n",
    "                    seq_list.append(curr_seq[:num_peds_considered])\n",
    "                    seq_list_rel.append(curr_seq_rel[:num_peds_considered])\n",
    "\n",
    "        self.num_seq = len(seq_list)\n",
    "        seq_list = np.concatenate(seq_list, axis=0)\n",
    "        seq_list_rel = np.concatenate(seq_list_rel, axis=0)\n",
    "        loss_mask_list = np.concatenate(loss_mask_list, axis=0)\n",
    "        non_linear_ped = np.asarray(non_linear_ped)\n",
    "\n",
    "        # Convert numpy -> Torch Tensor\n",
    "        self.obs_traj = torch.from_numpy(\n",
    "            seq_list[:, :, :self.obs_len]).type(torch.float)\n",
    "        self.pred_traj = torch.from_numpy(\n",
    "            seq_list[:, :, self.obs_len:]).type(torch.float)\n",
    "        self.obs_traj_rel = torch.from_numpy(\n",
    "            seq_list_rel[:, :, :self.obs_len]).type(torch.float)\n",
    "        self.pred_traj_rel = torch.from_numpy(\n",
    "            seq_list_rel[:, :, self.obs_len:]).type(torch.float)\n",
    "        self.loss_mask = torch.from_numpy(loss_mask_list).type(torch.float)\n",
    "        self.non_linear_ped = torch.from_numpy(non_linear_ped).type(torch.float)\n",
    "        cum_start_idx = [0] + np.cumsum(num_peds_in_seq).tolist()\n",
    "        self.seq_start_end = [\n",
    "            (start, end)\n",
    "            for start, end in zip(cum_start_idx, cum_start_idx[1:])\n",
    "        ]\n",
    "    def __len__(self):\n",
    "        return self.num_seq\n",
    "    def __getitem__(self, index):\n",
    "        start, end = self.seq_start_end[index]\n",
    "        out = [\n",
    "            self.obs_traj[start:end, :], self.pred_traj[start:end, :],\n",
    "            self.obs_traj_rel[start:end, :], self.pred_traj_rel[start:end, :],\n",
    "            self.non_linear_ped[start:end], self.loss_mask[start:end, :]\n",
    "        ]\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d73a866b-195a-4ff0-85b9-387793d9a0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "class CreateArg():\n",
    "    def __init__(self):\n",
    "        # Dataset options\n",
    "        self.dataset_name = 'waterloo'\n",
    "        self.delim = '\\t'\n",
    "        self.loader_num_workers = 4\n",
    "        self.obs_len = 8\n",
    "        self.pred_len = 8\n",
    "        self.skip = 1\n",
    "        # Optimization\n",
    "        self.batch_size = 4\n",
    "        self.num_iterations = 1000 # 10000\n",
    "        self.num_epochs = 50 # 200                     \n",
    "        # Model Options\n",
    "        self.embedding_dim = 64\n",
    "        self.num_layers = 1\n",
    "        self.dropout = 0.0\n",
    "        self.batch_norm = 0 \n",
    "        self.mlp_dim = 1024\n",
    "        # self.default_backbone= 'resnet18'\n",
    "                                    \n",
    "        # Generator Options\n",
    "        self.encoder_h_dim_g = 64\n",
    "        self.decoder_h_dim_g = 128\n",
    "        self.noise_dim : Tuple[int] = (0, 0) # default=None # type=int_tuple\n",
    "        self.noise_type = 'gaussian'\n",
    "        self.noise_mix_type = 'ped'\n",
    "        self.clipping_threshold_g = 0 # type=float\n",
    "        self.g_learning_rate = 5e-4 # type=float \n",
    "        self.g_steps = 1\n",
    "\n",
    "        # Pooling Options\n",
    "        self.pooling_type = 'pool_net' \n",
    "        self.pool_every_timestep = 1 # type=bool_flag\n",
    "\n",
    "        # Pool Net Option\n",
    "        self.bottleneck_dim = 1024 # type=int\n",
    "\n",
    "        # Social Pooling Options\n",
    "        self.neighborhood_size = 1024 # type=float\n",
    "        self.grid_size = 8 # type=int\n",
    "\n",
    "        # Discriminator Options\n",
    "        self.d_type = 'local' # type=str\n",
    "        self.encoder_h_dim_d = 64 # type=int\n",
    "        self.d_learning_rate = 5e-4 # type=float\n",
    "        self.d_steps = 2 # type=int        \n",
    "        self.clipping_threshold_d = 0 # type=float  \n",
    "\n",
    "        # Loss Options\n",
    "        self.l2_loss_weight = 0 # type=float \n",
    "        self.best_k = 1 # type=int \n",
    "\n",
    "        # Output\n",
    "        self.output_dir = os.getcwd()\n",
    "        self.print_every = 5 # type=int\n",
    "        self.checkpoint_every = 100 # type=int\n",
    "        self.checkpoint_name = 'checkpoint' \n",
    "        self.checkpoint_start_from = None\n",
    "        self.restore_from_checkpoint = 1 # type=int\n",
    "        self.num_samples_check = 5000 # type=int        \n",
    "\n",
    "        # Misc\n",
    "        self.use_gpu = 1 # type=int\n",
    "        self.timing = 0 # type=int\n",
    "        self.gpu_num = \"1\" # type=str   \n",
    "\n",
    "\n",
    "args = CreateArg() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "478748eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "# sys.path.append('/home/gpuadmin/dev/traj_pred/Trajectory_Prediction/traffino')\n",
    "sys.path.append('C:/Users/NGN/dev/Traffino/TRAFFINO/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a7f3d176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['temp.txt']\n",
      "C:/Users/NGN/dev/Traffino/TRAFFINO/traffino/datasets/waterloo/temp\\temp.txt\n"
     ]
    }
   ],
   "source": [
    "from data.loader_basic import data_loader # basic train을 위한 loader\n",
    "temp_path = 'C:/Users/NGN/dev/Traffino/TRAFFINO/traffino/datasets/waterloo/temp'\n",
    "logger.info(\"Initializing temp dataset\")\n",
    "train_dset, train_loader = data_loader(args, temp_path) # train_dset은 TrajectoryDataset, train_loader는 DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4f3bea03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "195\n",
      "49\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dset))\n",
    "print(len(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "83bd34cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.utils.data.dataloader.DataLoader'>\n"
     ]
    }
   ],
   "source": [
    "print(type(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "7a902dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Read 1-th data done\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "for batch in train_loader: # batch\n",
    "    print(i)\n",
    "\n",
    "    batch = [tensor.cuda() for tensor in batch]\n",
    "    (obs_traj, pred_traj_gt, obs_traj_rel, pred_traj_gt_rel, non_linear_ped,\n",
    "     loss_mask, seq_start_end) = batch\n",
    "    i+=1\n",
    "    if(i==1):\n",
    "        print(f'Read {i}-th data done')\n",
    "        break\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f2b8d8df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[10.3100,  5.9700],\n",
      "         [12.4900,  6.6000],\n",
      "         [ 9.5700,  6.2400],\n",
      "         [11.9400,  6.7700],\n",
      "         [ 8.7300,  6.3400],\n",
      "         [11.0300,  6.8400],\n",
      "         [11.8400,  5.8200],\n",
      "         [ 7.9400,  6.5000],\n",
      "         [10.2100,  6.8100],\n",
      "         [10.9100,  5.9200]],\n",
      "\n",
      "        [[ 9.5700,  6.2400],\n",
      "         [11.9400,  6.7700],\n",
      "         [ 8.7300,  6.3400],\n",
      "         [11.0300,  6.8400],\n",
      "         [ 7.9400,  6.5000],\n",
      "         [10.2100,  6.8100],\n",
      "         [10.9100,  5.9200],\n",
      "         [ 7.1700,  6.6200],\n",
      "         [ 9.3600,  6.8500],\n",
      "         [10.0000,  5.8900]],\n",
      "\n",
      "        [[ 8.7300,  6.3400],\n",
      "         [11.0300,  6.8400],\n",
      "         [ 7.9400,  6.5000],\n",
      "         [10.2100,  6.8100],\n",
      "         [ 7.1700,  6.6200],\n",
      "         [ 9.3600,  6.8500],\n",
      "         [10.0000,  5.8900],\n",
      "         [ 6.4700,  6.6800],\n",
      "         [ 8.5900,  6.8500],\n",
      "         [ 9.0900,  6.0200]],\n",
      "\n",
      "        [[ 7.9400,  6.5000],\n",
      "         [10.2100,  6.8100],\n",
      "         [ 7.1700,  6.6200],\n",
      "         [ 9.3600,  6.8500],\n",
      "         [ 6.4700,  6.6800],\n",
      "         [ 8.5900,  6.8500],\n",
      "         [ 9.0900,  6.0200],\n",
      "         [ 5.8600,  6.8200],\n",
      "         [ 7.7800,  6.8400],\n",
      "         [ 8.2300,  6.0400]],\n",
      "\n",
      "        [[ 7.1700,  6.6200],\n",
      "         [ 9.3600,  6.8500],\n",
      "         [ 6.4700,  6.6800],\n",
      "         [ 8.5900,  6.8500],\n",
      "         [ 5.8600,  6.8200],\n",
      "         [ 7.7800,  6.8400],\n",
      "         [ 8.2300,  6.0400],\n",
      "         [ 5.2400,  6.9800],\n",
      "         [ 6.9600,  6.8400],\n",
      "         [ 7.4000,  6.1500]],\n",
      "\n",
      "        [[ 6.4700,  6.6800],\n",
      "         [ 8.5900,  6.8500],\n",
      "         [ 5.8600,  6.8200],\n",
      "         [ 7.7800,  6.8400],\n",
      "         [ 5.2400,  6.9800],\n",
      "         [ 6.9600,  6.8400],\n",
      "         [ 7.4000,  6.1500],\n",
      "         [ 4.8700,  7.1600],\n",
      "         [ 6.2900,  7.0000],\n",
      "         [ 6.5200,  6.1500]],\n",
      "\n",
      "        [[ 5.8600,  6.8200],\n",
      "         [ 7.7800,  6.8400],\n",
      "         [ 5.2400,  6.9800],\n",
      "         [ 6.9600,  6.8400],\n",
      "         [ 4.8700,  7.1600],\n",
      "         [ 6.2900,  7.0000],\n",
      "         [ 6.5200,  6.1500],\n",
      "         [ 4.5100,  7.5800],\n",
      "         [ 5.6200,  7.1000],\n",
      "         [ 5.7000,  6.2100]],\n",
      "\n",
      "        [[ 5.2400,  6.9800],\n",
      "         [ 6.9600,  6.8400],\n",
      "         [ 4.8700,  7.1600],\n",
      "         [ 6.2900,  7.0000],\n",
      "         [ 4.5100,  7.5800],\n",
      "         [ 5.6200,  7.1000],\n",
      "         [ 5.7000,  6.2100],\n",
      "         [ 4.2000,  7.3000],\n",
      "         [ 5.0600,  7.0400],\n",
      "         [ 4.9600,  6.1000]]], device='cuda:0')\n",
      "len(obs_traj): 8\n",
      "3\n",
      "obs_traj.shape: torch.Size([8, 10, 2])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# obs_traj\n",
    "\n",
    "print(obs_traj)\n",
    "print(f\"len(obs_traj): {len(obs_traj)}\")\n",
    "print(obs_traj.ndim)\n",
    "print(f\"obs_traj.shape: {obs_traj.shape}\")\n",
    "print(type(obs_traj))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7509f07e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Read 1-th data done\n"
     ]
    }
   ],
   "source": [
    "j=0\n",
    "for batch in train_dset: # batch\n",
    "    print(j)\n",
    "\n",
    "    batch = [tensor.cuda() for tensor in batch]\n",
    "    (obs_traj_td, pred_traj_gt_td, obs_traj_rel_td, pred_traj_gt_rel_td, non_linear_ped_Td,\n",
    "     loss_mask_td) = batch\n",
    "    j+=1\n",
    "    if(j==1):\n",
    "        print(f'Read {j}-th data done')\n",
    "        break\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "aa90264c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[10.3100,  9.5700,  8.7300,  7.9400,  7.1700,  6.4700,  5.8600,\n",
      "           5.2400],\n",
      "         [ 5.9700,  6.2400,  6.3400,  6.5000,  6.6200,  6.6800,  6.8200,\n",
      "           6.9800]],\n",
      "\n",
      "        [[12.4900, 11.9400, 11.0300, 10.2100,  9.3600,  8.5900,  7.7800,\n",
      "           6.9600],\n",
      "         [ 6.6000,  6.7700,  6.8400,  6.8100,  6.8500,  6.8500,  6.8400,\n",
      "           6.8400]]], device='cuda:0')\n",
      "len(obs_traj_td): 2\n",
      "3\n",
      "obs_traj_td.shape: torch.Size([2, 2, 8])\n",
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "# obs_traj\n",
    "\n",
    "print(obs_traj_td)\n",
    "print(f\"len(obs_traj_td): {len(obs_traj_td)}\")\n",
    "print(obs_traj_td.ndim)\n",
    "print(f\"obs_traj_td.shape: {obs_traj_td.shape}\")\n",
    "print(type(obs_traj_td))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffino",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
