{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test \n",
    "# model wth state \n",
    "# date : 230902"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import os\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from attrdict import AttrDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/gpuadmin/dev/Trajectory_Prediction/traffino')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data.loader_state import data_loader\n",
    "from models_state import TrajectoryGenerator\n",
    "from losses import displacement_error, final_displacement_error\n",
    "from traffino.utils import relative_to_abs, get_dset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "class CreateArg():\n",
    "\n",
    "    def __init__(self):\n",
    "\n",
    "        # test\n",
    "        self.model_path = '/home/gpuadmin/dev/Trajectory_Prediction/traffino/output_12/state_output' \n",
    "        self.num_samples = 20 # type=int\n",
    "        self.dset_type = \"test\" # type=str   \n",
    "\n",
    "        # Dataset options\n",
    "        self.dataset_name = 'waterloo'\n",
    "        self.delim = '\\t'\n",
    "        self.loader_num_workers = 4\n",
    "        self.obs_len = 8\n",
    "        self.pred_len = 12 ############# check !!!\n",
    "        self.skip = 1\n",
    "        # Optimization\n",
    "        self.batch_size = 8\n",
    "        self.num_iterations = 1000 # 10000\n",
    "        self.num_epochs = 50 # 200                     \n",
    "        # Model Options\n",
    "        self.embedding_dim = 64\n",
    "        self.num_layers = 1\n",
    "        self.dropout = 0.0\n",
    "        self.batch_norm = 0 \n",
    "        self.mlp_dim = 1024\n",
    "        # self.default_backbone= 'resnet18'\n",
    "                                    \n",
    "        # Generator Options\n",
    "        self.encoder_h_dim_g = 64\n",
    "        self.decoder_h_dim_g = 128\n",
    "        self.noise_dim : Tuple[int] = (0, 0) # default=None # type=int_tuple\n",
    "        self.noise_type = 'gaussian'\n",
    "        self.noise_mix_type = 'ped'\n",
    "        self.clipping_threshold_g = 0 # type=float\n",
    "        self.g_learning_rate = 5e-4 # type=float \n",
    "        self.g_steps = 1\n",
    "\n",
    "        # Pooling Options\n",
    "        self.pooling_type = 'pool_net' \n",
    "        self.pool_every_timestep = 1 # type=bool_flag\n",
    "\n",
    "        # Pool Net Option\n",
    "        self.bottleneck_dim = 1024 # type=int\n",
    "\n",
    "        # Social Pooling Options\n",
    "        self.neighborhood_size = 1024 # type=float\n",
    "        self.grid_size = 8 # type=int\n",
    "\n",
    "        # Discriminator Options\n",
    "        self.d_type = 'local' # type=str\n",
    "        self.encoder_h_dim_d = 64 # type=int\n",
    "        self.d_learning_rate = 5e-4 # type=float\n",
    "        self.d_steps = 2 # type=int        \n",
    "        self.clipping_threshold_d = 0 # type=float  \n",
    "\n",
    "        # Loss Options\n",
    "        self.l2_loss_weight = 0 # type=float \n",
    "        self.best_k = 1 # type=int \n",
    "\n",
    "        # Output\n",
    "        self.output_dir = os.getcwd()+'/state_output'\n",
    "        self.print_every = 5 # type=int\n",
    "        self.checkpoint_every = 100 # type=int\n",
    "        self.checkpoint_name = 'checkpoint_state' \n",
    "        self.checkpoint_start_from = None\n",
    "        self.restore_from_checkpoint = 1 # type=int\n",
    "        self.num_samples_check = 5000 # type=int        \n",
    "\n",
    "        # Misc\n",
    "        self.use_gpu = 1 # type=int\n",
    "        self.timing = 0 # type=int\n",
    "        self.gpu_num = \"1\" # type=str   \n",
    "\n",
    "\n",
    "args = CreateArg() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_generator(checkpoint):\n",
    "    args_ = args\n",
    "    generator = TrajectoryGenerator(\n",
    "        obs_len=args_.obs_len,\n",
    "        pred_len=args_.pred_len,\n",
    "        embedding_dim=args_.embedding_dim,\n",
    "        encoder_h_dim=args_.encoder_h_dim_g,\n",
    "        decoder_h_dim=args_.decoder_h_dim_g,\n",
    "        mlp_dim=args_.mlp_dim,\n",
    "        num_layers=args_.num_layers,\n",
    "        noise_dim=args_.noise_dim,\n",
    "        noise_type=args_.noise_type,\n",
    "        noise_mix_type=args_.noise_mix_type,\n",
    "        pooling_type=args_.pooling_type,\n",
    "        pool_every_timestep=args_.pool_every_timestep,\n",
    "        dropout=args_.dropout,\n",
    "        bottleneck_dim=args_.bottleneck_dim,\n",
    "        neighborhood_size=args_.neighborhood_size,\n",
    "        # grid_size=args_.grid_size,\n",
    "        batch_norm=args_.batch_norm)\n",
    "    generator.load_state_dict(checkpoint['g_state'])\n",
    "    generator.cuda()\n",
    "    generator.train()\n",
    "    return generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_helper(error, seq_start_end):\n",
    "    sum_ = 0\n",
    "    error = torch.stack(error, dim=1)\n",
    "\n",
    "    for (start, end) in seq_start_end:\n",
    "        start = start.item()\n",
    "        end = end.item()\n",
    "        _error = error[start:end]\n",
    "        _error = torch.sum(_error, dim=0)\n",
    "        _error = torch.min(_error)\n",
    "        sum_ += _error\n",
    "    return sum_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(args, loader, generator, num_samples):\n",
    "    ade_outer, fde_outer = [], []\n",
    "    total_traj = 0\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = [tensor.cuda() for tensor in batch]\n",
    "            # (obs_traj, pred_traj_gt, obs_traj_rel, pred_traj_gt_rel,\n",
    "            #  non_linear_ped, loss_mask, seq_start_end) = batch\n",
    "\n",
    "            (obs_traj, obs_state, _,\n",
    "     \n",
    "            pred_traj_gt, _, _,\n",
    "            \n",
    "            obs_traj_rel, pred_traj_gt_rel, \n",
    "            \n",
    "            _, loss_mask, seq_start_end \n",
    "            ) = batch\n",
    "\n",
    "            ade, fde = [], []\n",
    "            total_traj += pred_traj_gt.size(1)\n",
    "\n",
    "            for _ in range(num_samples):\n",
    "                pred_traj_fake_rel = generator(\n",
    "                    obs_traj, obs_traj_rel, seq_start_end,\n",
    "                    obs_state\n",
    "                )\n",
    "                pred_traj_fake = relative_to_abs(\n",
    "                    pred_traj_fake_rel, obs_traj[-1]\n",
    "                )\n",
    "                ade.append(displacement_error(\n",
    "                    pred_traj_fake, pred_traj_gt, mode='raw'\n",
    "                ))\n",
    "                fde.append(final_displacement_error(\n",
    "                    pred_traj_fake[-1], pred_traj_gt[-1], mode='raw'\n",
    "                ))\n",
    "\n",
    "            ade_sum = evaluate_helper(ade, seq_start_end)\n",
    "            fde_sum = evaluate_helper(fde, seq_start_end)\n",
    "\n",
    "            ade_outer.append(ade_sum)\n",
    "            fde_outer.append(fde_sum)\n",
    "        ade = sum(ade_outer) / (total_traj * args.pred_len)\n",
    "        fde = sum(fde_outer) / (total_traj)\n",
    "        return ade, fde\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['checkpoint_state_with_model.pt']\n"
     ]
    }
   ],
   "source": [
    "if os.path.isdir(args.model_path):\n",
    "    filenames = os.listdir(args.model_path)\n",
    "    print(filenames)\n",
    "    filenames.sort()\n",
    "    paths = [\n",
    "        os.path.join(args.model_path, file_) for file_ in filenames\n",
    "    ]\n",
    "else:\n",
    "    paths = [args.model_path]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/gpuadmin/dev/Trajectory_Prediction/traffino/output_12/state_output\n",
      "['checkpoint_state_with_model.pt']\n",
      "['/home/gpuadmin/dev/Trajectory_Prediction/traffino/output_12/state_output/checkpoint_state_with_model.pt']\n",
      "args.pred_len:12\n",
      "args.batch_size:8\n"
     ]
    }
   ],
   "source": [
    "print(args.model_path)\n",
    "print(filenames)\n",
    "print(paths)\n",
    "print(f\"args.pred_len:{args.pred_len}\")\n",
    "print(f\"args.batch_size:{args.batch_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "['0785_prep.txt', '0784_prep.txt']\n",
      "/home/gpuadmin/dev/Trajectory_Prediction/traffino/datasets/waterloo/test/0784_prep.txt\n",
      "/home/gpuadmin/dev/Trajectory_Prediction/traffino/datasets/waterloo/test2/0784_prep2.txt\n",
      "/home/gpuadmin/dev/Trajectory_Prediction/traffino/datasets/waterloo/test2/0784_prep3.txt\n",
      "/home/gpuadmin/dev/Trajectory_Prediction/traffino/datasets/waterloo/test/0785_prep.txt\n",
      "/home/gpuadmin/dev/Trajectory_Prediction/traffino/datasets/waterloo/test2/0785_prep2.txt\n",
      "/home/gpuadmin/dev/Trajectory_Prediction/traffino/datasets/waterloo/test2/0785_prep3.txt\n",
      "Dataset: waterloo, Pred Len: 12, ADE: 12.65, FDE: 25.43\n"
     ]
    }
   ],
   "source": [
    "for path in paths:\n",
    "    # print(path)\n",
    "    checkpoint = torch.load(path)\n",
    "    # print(f\"checkpoint: {checkpoint}\\n\")\n",
    "    print(\"\\n\")\n",
    "    generator = get_generator(checkpoint)\n",
    "    #_args = AttrDict(checkpoint['args'])\n",
    "    path = '/home/gpuadmin/dev/Trajectory_Prediction/traffino/datasets/waterloo/test'\n",
    "    _, loader = data_loader(args, path)\n",
    "    ade, fde = evaluate(args, loader, generator, args.num_samples)\n",
    "    print('Dataset: {}, Pred Len: {}, ADE: {:.2f}, FDE: {:.2f}'.format(\n",
    "        args.dataset_name, args.pred_len, ade, fde))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffino",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
