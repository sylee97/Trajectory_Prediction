{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### test for train ###\n",
    "# 230902\n",
    "# dataset 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/home/gpuadmin/dev/Trajectory_Prediction/traffino')\n",
    "\n",
    "import argparse\n",
    "import gc\n",
    "import logging\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from data.loader_basic import data_loader # basic train을 위한 loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from losses import gan_g_loss, gan_d_loss, l2_loss\n",
    "from losses import displacement_error, final_displacement_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from traffino.model_basic import TrajectoryGenerator, TrajectoryDiscriminator\n",
    "from traffino.utils import int_tuple, bool_flag, get_total_norm\n",
    "from traffino.utils import relative_to_abs, get_dset_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.backends.cudnn.benchmark = True # cudnn의 benchmark를 통해 최적 backend 연산을 찾는 flag를 true로 하겠음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "FORMAT = '[%(levelname)s: %(filename)s: %(lineno)4d]: %(message)s'\n",
    "logging.basicConfig(level=logging.INFO, format=FORMAT, stream=sys.stdout)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "class CreateArg():\n",
    "    def __init__(self):\n",
    "        # Dataset options\n",
    "        self.dataset_name = 'waterloo'\n",
    "        self.delim = '\\t'\n",
    "        self.loader_num_workers = 4\n",
    "        self.obs_len = 8 # 8 timestep\n",
    "        self.pred_len = 8   \n",
    "        self.skip = 1\n",
    "        # Optimization\n",
    "        self.batch_size = 8                    ##### batch_size test !!!\n",
    "        self.num_iterations = 1000 # 10000\n",
    "        self.num_epochs = 50 # 200                     \n",
    "        # Model Options\n",
    "        self.embedding_dim = 64\n",
    "        self.num_layers = 1\n",
    "        self.dropout = 0.0\n",
    "        self.batch_norm = 0 \n",
    "        self.mlp_dim = 1024\n",
    "        # self.default_backbone= 'resnet18'\n",
    "                                    \n",
    "        # Generator Options\n",
    "        self.encoder_h_dim_g = 64\n",
    "        self.decoder_h_dim_g = 128\n",
    "        self.noise_dim : Tuple[int] = (0, 0) # default=None # type=int_tuple\n",
    "        self.noise_type = 'gaussian'\n",
    "        self.noise_mix_type = 'ped'\n",
    "        self.clipping_threshold_g = 0 # type=float\n",
    "        self.g_learning_rate = 5e-4 # type=float \n",
    "        self.g_steps = 1\n",
    "\n",
    "        # Pooling Options\n",
    "        self.pooling_type = 'pool_net' \n",
    "        self.pool_every_timestep = 1 # type=bool_flag\n",
    "\n",
    "        # Pool Net Option\n",
    "        self.bottleneck_dim = 1024 # type=int\n",
    "\n",
    "        # Social Pooling Options\n",
    "        self.neighborhood_size = 1024 # type=float\n",
    "        self.grid_size = 8 # type=int\n",
    "\n",
    "        # Discriminator Options\n",
    "        self.d_type = 'local' # type=str\n",
    "        self.encoder_h_dim_d = 64 # type=int\n",
    "        self.d_learning_rate = 5e-4 # type=float\n",
    "        self.d_steps = 2 # type=int        \n",
    "        self.clipping_threshold_d = 0 # type=float  \n",
    "\n",
    "        # Loss Options\n",
    "        self.l2_loss_weight = 0 # type=float \n",
    "        self.best_k = 1 # type=int \n",
    "\n",
    "        # Output\n",
    "        self.output_dir = os.getcwd() + '/output/basic_output'\n",
    "        self.print_every = 5 # type=int\n",
    "        self.checkpoint_every = 100 # type=int\n",
    "        self.checkpoint_name = 'checkpoint' \n",
    "        self.checkpoint_start_from = None\n",
    "        self.restore_from_checkpoint = 1 # type=int\n",
    "        self.num_samples_check = 5000 # type=int        \n",
    "\n",
    "        # Misc\n",
    "        self.use_gpu = 1 # type=int\n",
    "        self.timing = 0 # type=int\n",
    "        self.gpu_num = \"1\" # type=str   \n",
    "\n",
    "\n",
    "args = CreateArg() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(args.batch_size)\n",
    "print(args.num_iterations)\n",
    "print(args.checkpoint_name)\n",
    "print(args.output_dir)\n",
    "print(args.restore_from_checkpoint )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        nn.init.kaiming_normal_(m.weight)\n",
    "\n",
    "\n",
    "def get_dtypes(args):\n",
    "    long_dtype = torch.LongTensor\n",
    "    float_dtype = torch.FloatTensor\n",
    "    if args.use_gpu == 1:\n",
    "    # use_gpu == 1:\n",
    "        long_dtype = torch.cuda.LongTensor\n",
    "        float_dtype = torch.cuda.FloatTensor\n",
    "    return long_dtype, float_dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_dtype, float_dtype = get_dtypes(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path = '/home/gpuadmin/dev/Trajectory_Prediction/traffino/datasets/waterloo/train/'\n",
    "\n",
    "# val_path = get_dset_path(args.dataset_name, 'val')\n",
    "\n",
    "val_path = '/home/gpuadmin/dev/Trajectory_Prediction/traffino/datasets/waterloo/val/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Initializing train dataset\")\n",
    "train_dset, train_loader = data_loader(args, train_path) # train_dset은 TrajectoryDataset, train_loader는 DataLoader (batch 단위로 변경)\n",
    "\n",
    "logger.info(\"Initializing val dataset\")\n",
    "_, val_loader = data_loader(args, val_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dset) # self.num_seq (727) --> iterations_per_epoch 계산하기 위해 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dset.num_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterations_per_epoch = len(train_dset) / args.batch_size / args.d_steps\n",
    "if args.num_epochs:\n",
    "    args.num_iterations = int(iterations_per_epoch * args.num_epochs)\n",
    "\n",
    "logger.info(\n",
    "    'There are {} iterations per epoch'.format(iterations_per_epoch)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = TrajectoryGenerator(\n",
    "    obs_len=args.obs_len,\n",
    "    pred_len=args.pred_len,\n",
    "    embedding_dim=args.embedding_dim,\n",
    "    encoder_h_dim=args.encoder_h_dim_g,\n",
    "    decoder_h_dim=args.decoder_h_dim_g,\n",
    "    mlp_dim=args.mlp_dim,\n",
    "    num_layers=args.num_layers,\n",
    "    noise_dim=args.noise_dim,\n",
    "    bottleneck_dim=args.bottleneck_dim,\n",
    "    noise_type=args.noise_type,\n",
    "    noise_mix_type=args.noise_mix_type,\n",
    "    pooling_type=args.pooling_type,\n",
    "    pool_every_timestep=args.pool_every_timestep,\n",
    "    dropout=args.dropout,\n",
    "    activation = 'relu',\n",
    "    batch_norm = args.batch_norm,\n",
    "    neighborhood_size=args.neighborhood_size,\n",
    "    # default_backbone = args.default_backbone\n",
    "    # grid_size=args.grid_size\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.apply(init_weights)\n",
    "generator.type(float_dtype).train()\n",
    "logger.info('Here is the generator:')\n",
    "logger.info(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator = TrajectoryDiscriminator(\n",
    "    obs_len=args.obs_len,\n",
    "    pred_len=args.pred_len,\n",
    "    embedding_dim=args.embedding_dim,\n",
    "    h_dim=args.encoder_h_dim_d,\n",
    "    mlp_dim=args.mlp_dim,\n",
    "    num_layers=args.num_layers,\n",
    "    dropout=args.dropout,\n",
    "    batch_norm=args.batch_norm,\n",
    "    d_type=args.d_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator.apply(init_weights)\n",
    "discriminator.type(float_dtype).train()\n",
    "logger.info('Here is the discriminator:')\n",
    "logger.info(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g_loss_fn = gan_g_loss\n",
    "d_loss_fn = gan_d_loss\n",
    "\n",
    "optimizer_g = optim.Adam(generator.parameters(), lr=args.g_learning_rate)\n",
    "optimizer_d = optim.Adam(\n",
    "    discriminator.parameters(), lr=args.d_learning_rate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args.restore_from_checkpoint = 1 #default : 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Maybe restore from checkpoint\n",
    "restore_path = None\n",
    "if args.checkpoint_start_from is not None:\n",
    "    restore_path = args.checkpoint_start_from\n",
    "elif args.restore_from_checkpoint == 1:\n",
    "    restore_path = os.path.join(args.output_dir,              # basic\n",
    "                                '%s_with_model.pt' % args.checkpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(restore_path) #checkpoint 불러오는 path\n",
    "print(os.path.isfile(restore_path)) #checkpoint 불러오는 path 파일이 있는지 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if restore_path is not None and os.path.isfile(restore_path): # restore 할 파일이 있으면\n",
    "    logger.info('Restoring from checkpoint {}'.format(restore_path))\n",
    "    checkpoint = torch.load(restore_path)\n",
    "    generator.load_state_dict(checkpoint['g_state'])\n",
    "    discriminator.load_state_dict(checkpoint['d_state'])\n",
    "    optimizer_g.load_state_dict(checkpoint['g_optim_state'])\n",
    "    optimizer_d.load_state_dict(checkpoint['d_optim_state'])\n",
    "    t = checkpoint['counters']['t']\n",
    "    epoch = checkpoint['counters']['epoch']\n",
    "    checkpoint['restore_ts'].append(t)\n",
    "    \n",
    "else:\n",
    "    # Starting from scratch, so initialize checkpoint data structure\n",
    "    t, epoch = 0, 0\n",
    "    checkpoint = {\n",
    "        'args': args.__dict__,\n",
    "        'G_losses': defaultdict(list),\n",
    "        'D_losses': defaultdict(list),\n",
    "        'losses_ts': [],\n",
    "        'metrics_val': defaultdict(list),\n",
    "        'metrics_train': defaultdict(list),\n",
    "        'sample_ts': [],\n",
    "        'restore_ts': [],\n",
    "        'norm_g': [],\n",
    "        'norm_d': [],\n",
    "        'counters': {\n",
    "            't': None,\n",
    "            'epoch': None,\n",
    "        },\n",
    "        'g_state': None,\n",
    "        'g_optim_state': None,\n",
    "        'd_state': None,\n",
    "        'd_optim_state': None,\n",
    "        'g_best_state': None,\n",
    "        'd_best_state': None,\n",
    "        'best_t': None,\n",
    "        'g_best_nl_state': None,\n",
    "        'd_best_state_nl': None,\n",
    "        'best_t_nl': None,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t0 = None\n",
    "while t < args.num_iterations: # 10000\n",
    "    gc.collect()\n",
    "    d_steps_left = args.d_steps # 2\n",
    "    g_steps_left = args.g_steps # 1\n",
    "    epoch += 1\n",
    "    logger.info('Starting epoch {}'.format(epoch))\n",
    "    for batch in train_loader: # batch\n",
    "        if args.timing == 1: # default = 0\n",
    "            torch.cuda.synchronize()\n",
    "            t1 = time.time()\n",
    "\n",
    "        # Decide whether to use the batch for stepping on discriminator or\n",
    "        # generator; an iteration consists of args.d_steps steps on the\n",
    "        # discriminator followed by args.g_steps steps on the generator.\n",
    "        \n",
    "        if d_steps_left > 0:\n",
    "            step_type = 'd'\n",
    "            losses_d = discriminator_step(args, batch, generator,\n",
    "                                            discriminator, d_loss_fn,\n",
    "                                            optimizer_d)\n",
    "            checkpoint['norm_d'].append(\n",
    "                get_total_norm(discriminator.parameters()))\n",
    "            d_steps_left -= 1\n",
    "            \n",
    "        elif g_steps_left > 0:\n",
    "            step_type = 'g'\n",
    "            losses_g = generator_step(args, batch, generator,\n",
    "                                        discriminator, g_loss_fn, # g_loss_fn = gan_g_loss\n",
    "                                        optimizer_g)\n",
    "            \n",
    "            checkpoint['norm_g'].append(\n",
    "                get_total_norm(generator.parameters())\n",
    "            )\n",
    "            g_steps_left -= 1\n",
    "\n",
    "        if args.timing == 1:\n",
    "            torch.cuda.synchronize()\n",
    "            t2 = time.time()\n",
    "            logger.info('{} step took {}'.format(step_type, t2 - t1))\n",
    "\n",
    "        # Skip the rest if we are not at the end of an iteration\n",
    "        if d_steps_left > 0 or g_steps_left > 0:\n",
    "            continue\n",
    "\n",
    "        if args.timing == 1:\n",
    "            if t0 is not None:\n",
    "                logger.info('Interation {} took {}'.format(\n",
    "                    t - 1, time.time() - t0\n",
    "                ))\n",
    "            t0 = time.time()\n",
    "\n",
    "        # Maybe save loss\n",
    "        if t % args.print_every == 0:\n",
    "            logger.info('t = {} / {}'.format(t + 1, args.num_iterations))\n",
    "            for k, v in sorted(losses_d.items()):\n",
    "                logger.info('  [D] {}: {:.3f}'.format(k, v))\n",
    "                checkpoint['D_losses'][k].append(v)\n",
    "            for k, v in sorted(losses_g.items()):\n",
    "                logger.info('  [G] {}: {:.3f}'.format(k, v))\n",
    "                checkpoint['G_losses'][k].append(v)\n",
    "            checkpoint['losses_ts'].append(t)\n",
    "\n",
    "        # Maybe save a checkpoint\n",
    "        if t > 0 and t % args.checkpoint_every == 0:\n",
    "            checkpoint['counters']['t'] = t\n",
    "            checkpoint['counters']['epoch'] = epoch\n",
    "            checkpoint['sample_ts'].append(t)\n",
    "\n",
    "            # Check stats on the validation set\n",
    "            logger.info('Checking stats on val ...')\n",
    "            metrics_val = check_accuracy(\n",
    "                args, val_loader, generator, discriminator, \n",
    "                d_loss_fn, limit=False\n",
    "            )\n",
    "            logger.info('Checking stats on train ...')\n",
    "            metrics_train = check_accuracy(\n",
    "                args, train_loader, generator, discriminator,\n",
    "                d_loss_fn, limit=True\n",
    "            )\n",
    "\n",
    "            for k, v in sorted(metrics_val.items()):\n",
    "                logger.info('  [val] {}: {:.3f}'.format(k, v))\n",
    "                checkpoint['metrics_val'][k].append(v)\n",
    "                \n",
    "            for k, v in sorted(metrics_train.items()):\n",
    "                logger.info('  [train] {}: {:.3f}'.format(k, v))\n",
    "                checkpoint['metrics_train'][k].append(v)\n",
    "\n",
    "            min_ade = min(checkpoint['metrics_val']['ade'])\n",
    "            min_ade_nl = min(checkpoint['metrics_val']['ade_nl'])\n",
    "\n",
    "            if metrics_val['ade'] == min_ade:\n",
    "                logger.info('New low for avg_disp_error')\n",
    "                checkpoint['best_t'] = t\n",
    "                checkpoint['g_best_state'] = generator.state_dict()\n",
    "                checkpoint['d_best_state'] = discriminator.state_dict()\n",
    "\n",
    "            if metrics_val['ade_nl'] == min_ade_nl:\n",
    "                logger.info('New low for avg_disp_error_nl')\n",
    "                checkpoint['best_t_nl'] = t\n",
    "                checkpoint['g_best_nl_state'] = generator.state_dict()\n",
    "                checkpoint['d_best_nl_state'] = discriminator.state_dict()\n",
    "\n",
    "            # Save another checkpoint with model weights and\n",
    "            # optimizer state\n",
    "            checkpoint['g_state'] = generator.state_dict()\n",
    "            checkpoint['g_optim_state'] = optimizer_g.state_dict()\n",
    "            checkpoint['d_state'] = discriminator.state_dict()\n",
    "            checkpoint['d_optim_state'] = optimizer_d.state_dict()\n",
    "            \n",
    "            checkpoint_path = os.path.join(\n",
    "                args.output_dir, '%s_with_model.pt' % args.checkpoint_name\n",
    "            )\n",
    "            \n",
    "            logger.info('Saving checkpoint to {}'.format(checkpoint_path))\n",
    "            torch.save(checkpoint, checkpoint_path)\n",
    "            logger.info('Done.')\n",
    "\n",
    "            # Save a checkpoint with no model weights by making a shallow\n",
    "            # copy of the checkpoint excluding some items\n",
    "            \n",
    "            checkpoint_path = os.path.join(\n",
    "                args.output_dir, '%s_no_model.pt' % args.checkpoint_name)\n",
    "            \n",
    "            logger.info('Saving checkpoint to {}'.format(checkpoint_path))\n",
    "            \n",
    "            key_blacklist = [\n",
    "                'g_state', 'd_state', 'g_best_state', 'g_best_nl_state',\n",
    "                'g_optim_state', 'd_optim_state', 'd_best_state',\n",
    "                'd_best_nl_state'\n",
    "            ]\n",
    "            \n",
    "            small_checkpoint = {}\n",
    "            for k, v in checkpoint.items():\n",
    "                if k not in key_blacklist:\n",
    "                    small_checkpoint[k] = v\n",
    "            torch.save(small_checkpoint, checkpoint_path)\n",
    "            logger.info('Done.')\n",
    "\n",
    "        t += 1\n",
    "        d_steps_left = args.d_steps\n",
    "        \n",
    "        g_steps_left = args.g_steps\n",
    "        if t >= args.num_iterations:\n",
    "            break\n",
    "\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator_step(\n",
    "    args, batch, generator, discriminator, g_loss_fn, optimizer_g\n",
    "):\n",
    "    batch = [tensor.cuda() for tensor in batch]\n",
    "    (obs_traj, pred_traj_gt, obs_traj_rel, pred_traj_gt_rel, non_linear_ped,\n",
    "     loss_mask, seq_start_end) = batch\n",
    "    \n",
    "    losses = {}\n",
    "    loss = torch.zeros(1).to(pred_traj_gt)\n",
    "    g_l2_loss_rel = []\n",
    "\n",
    "    loss_mask = loss_mask[:, args.obs_len:]\n",
    "\n",
    "    for _ in range(args.best_k):\n",
    "        generator_out = generator(obs_traj, obs_traj_rel, seq_start_end)\n",
    "\n",
    "        pred_traj_fake_rel = generator_out\n",
    "        pred_traj_fake = relative_to_abs(pred_traj_fake_rel, obs_traj[-1])\n",
    "\n",
    "        if args.l2_loss_weight > 0:\n",
    "            g_l2_loss_rel.append(args.l2_loss_weight * l2_loss(\n",
    "                pred_traj_fake_rel,\n",
    "                pred_traj_gt_rel,\n",
    "                loss_mask,\n",
    "                mode='raw'))\n",
    "\n",
    "    g_l2_loss_sum_rel = torch.zeros(1).to(pred_traj_gt)\n",
    "    if args.l2_loss_weight > 0:\n",
    "        g_l2_loss_rel = torch.stack(g_l2_loss_rel, dim=1)\n",
    "        for start, end in seq_start_end.data:\n",
    "            _g_l2_loss_rel = g_l2_loss_rel[start:end]\n",
    "            _g_l2_loss_rel = torch.sum(_g_l2_loss_rel, dim=0)\n",
    "            _g_l2_loss_rel = torch.min(_g_l2_loss_rel) / torch.sum(\n",
    "                loss_mask[start:end])\n",
    "            g_l2_loss_sum_rel += _g_l2_loss_rel\n",
    "        losses['G_l2_loss_rel'] = g_l2_loss_sum_rel.item()\n",
    "        loss += g_l2_loss_sum_rel\n",
    "\n",
    "    traj_fake = torch.cat([obs_traj, pred_traj_fake], dim=0)\n",
    "    traj_fake_rel = torch.cat([obs_traj_rel, pred_traj_fake_rel], dim=0)\n",
    "\n",
    "    scores_fake = discriminator(traj_fake, traj_fake_rel, seq_start_end)\n",
    "    discriminator_loss = g_loss_fn(scores_fake)\n",
    "\n",
    "    loss += discriminator_loss\n",
    "    losses['G_discriminator_loss'] = discriminator_loss.item()\n",
    "    losses['G_total_loss'] = loss.item()\n",
    "\n",
    "    optimizer_g.zero_grad()\n",
    "    loss.backward()\n",
    "    if args.clipping_threshold_g > 0:\n",
    "        nn.utils.clip_grad_norm_(\n",
    "            generator.parameters(), args.clipping_threshold_g\n",
    "        )\n",
    "    optimizer_g.step()\n",
    "\n",
    "    return losses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def discriminator_step(\n",
    "    args, batch, generator, discriminator, d_loss_fn, optimizer_d\n",
    "):\n",
    "    batch = [tensor.cuda() for tensor in batch]\n",
    "    (obs_traj, pred_traj_gt, obs_traj_rel, pred_traj_gt_rel, non_linear_ped,\n",
    "     loss_mask, seq_start_end) = batch\n",
    "    losses = {}\n",
    "    loss = torch.zeros(1).to(pred_traj_gt)\n",
    "\n",
    "    generator_out = generator(obs_traj, obs_traj_rel, seq_start_end)\n",
    "    \n",
    "    pred_traj_fake_rel = generator_out\n",
    "    pred_traj_fake = relative_to_abs(pred_traj_fake_rel, obs_traj[-1])\n",
    "\n",
    "    traj_real = torch.cat([obs_traj, pred_traj_gt], dim=0) # Sizes of tensors must match except in dimension 0. Expected size 2 but got size 4 for tensor number 1 in the list.\n",
    "    traj_real_rel = torch.cat([obs_traj_rel, pred_traj_gt_rel], dim=0)\n",
    "    traj_fake = torch.cat([obs_traj, pred_traj_fake], dim=0)\n",
    "    traj_fake_rel = torch.cat([obs_traj_rel, pred_traj_fake_rel], dim=0)\n",
    "\n",
    "    scores_fake = discriminator(traj_fake, traj_fake_rel, seq_start_end)\n",
    "    scores_real = discriminator(traj_real, traj_real_rel, seq_start_end)\n",
    "\n",
    "    # Compute loss with optional gradient penalty\n",
    "    data_loss = d_loss_fn(scores_real, scores_fake)\n",
    "    losses['D_data_loss'] = data_loss.item()\n",
    "    loss += data_loss\n",
    "    losses['D_total_loss'] = loss.item()\n",
    "\n",
    "    optimizer_d.zero_grad()\n",
    "    loss.backward()\n",
    "    if args.clipping_threshold_d > 0:\n",
    "        nn.utils.clip_grad_norm_(discriminator.parameters(),\n",
    "                                 args.clipping_threshold_d)\n",
    "    optimizer_d.step()\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy(\n",
    "    args, loader, generator, discriminator, d_loss_fn, limit=False\n",
    "):\n",
    "    d_losses = []\n",
    "    metrics = {}\n",
    "    g_l2_losses_abs, g_l2_losses_rel = ([],) * 2\n",
    "    disp_error, disp_error_l, disp_error_nl = ([],) * 3\n",
    "    f_disp_error, f_disp_error_l, f_disp_error_nl = ([],) * 3\n",
    "    total_traj, total_traj_l, total_traj_nl = 0, 0, 0\n",
    "    loss_mask_sum = 0\n",
    "    generator.eval()\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            batch = [tensor.cuda() for tensor in batch]\n",
    "            (obs_traj, pred_traj_gt, obs_traj_rel, pred_traj_gt_rel,\n",
    "             non_linear_ped, loss_mask, seq_start_end) = batch\n",
    "\n",
    "\n",
    "            linear_ped = 1 - non_linear_ped\n",
    "            loss_mask = loss_mask[:, args.obs_len:]\n",
    "\n",
    "            pred_traj_fake_rel = generator(\n",
    "                obs_traj, obs_traj_rel, seq_start_end\n",
    "            )\n",
    "            pred_traj_fake = relative_to_abs(pred_traj_fake_rel, obs_traj[-1])\n",
    "\n",
    "            g_l2_loss_abs, g_l2_loss_rel = cal_l2_losses(\n",
    "                pred_traj_gt, pred_traj_gt_rel, pred_traj_fake,\n",
    "                pred_traj_fake_rel, loss_mask\n",
    "            )\n",
    "            ade, ade_l, ade_nl = cal_ade(\n",
    "                pred_traj_gt, pred_traj_fake, linear_ped, non_linear_ped\n",
    "            )\n",
    "\n",
    "            fde, fde_l, fde_nl = cal_fde(\n",
    "                pred_traj_gt, pred_traj_fake, linear_ped, non_linear_ped\n",
    "            )\n",
    "\n",
    "            traj_real = torch.cat([obs_traj, pred_traj_gt], dim=0)\n",
    "            traj_real_rel = torch.cat([obs_traj_rel, pred_traj_gt_rel], dim=0)\n",
    "            traj_fake = torch.cat([obs_traj, pred_traj_fake], dim=0)\n",
    "            traj_fake_rel = torch.cat([obs_traj_rel, pred_traj_fake_rel], dim=0)\n",
    "\n",
    "            scores_fake = discriminator(traj_fake, traj_fake_rel, seq_start_end)\n",
    "            scores_real = discriminator(traj_real, traj_real_rel, seq_start_end)\n",
    "\n",
    "            d_loss = d_loss_fn(scores_real, scores_fake)\n",
    "            d_losses.append(d_loss.item())\n",
    "\n",
    "            g_l2_losses_abs.append(g_l2_loss_abs.item())\n",
    "            g_l2_losses_rel.append(g_l2_loss_rel.item())\n",
    "            disp_error.append(ade.item())\n",
    "            disp_error_l.append(ade_l.item())\n",
    "            disp_error_nl.append(ade_nl.item())\n",
    "            f_disp_error.append(fde.item())\n",
    "            f_disp_error_l.append(fde_l.item())\n",
    "            f_disp_error_nl.append(fde_nl.item())\n",
    "\n",
    "            loss_mask_sum += torch.numel(loss_mask.data)\n",
    "            total_traj += pred_traj_gt.size(1)\n",
    "            total_traj_l += torch.sum(linear_ped).item()\n",
    "            total_traj_nl += torch.sum(non_linear_ped).item()\n",
    "            if limit and total_traj >= args.num_samples_check:\n",
    "                break\n",
    "\n",
    "    metrics['d_loss'] = sum(d_losses) / len(d_losses)\n",
    "    metrics['g_l2_loss_abs'] = sum(g_l2_losses_abs) / loss_mask_sum\n",
    "    metrics['g_l2_loss_rel'] = sum(g_l2_losses_rel) / loss_mask_sum\n",
    "\n",
    "    metrics['ade'] = sum(disp_error) / (total_traj * args.pred_len)\n",
    "    metrics['fde'] = sum(f_disp_error) / total_traj\n",
    "    if total_traj_l != 0:\n",
    "        metrics['ade_l'] = sum(disp_error_l) / (total_traj_l * args.pred_len)\n",
    "        metrics['fde_l'] = sum(f_disp_error_l) / total_traj_l\n",
    "    else:\n",
    "        metrics['ade_l'] = 0\n",
    "        metrics['fde_l'] = 0\n",
    "    if total_traj_nl != 0:\n",
    "        metrics['ade_nl'] = sum(disp_error_nl) / (\n",
    "            total_traj_nl * args.pred_len)\n",
    "        metrics['fde_nl'] = sum(f_disp_error_nl) / total_traj_nl\n",
    "    else:\n",
    "        metrics['ade_nl'] = 0\n",
    "        metrics['fde_nl'] = 0\n",
    "\n",
    "    generator.train()\n",
    "    return metrics\n",
    "\n",
    "\n",
    "def cal_l2_losses(\n",
    "    pred_traj_gt, pred_traj_gt_rel, pred_traj_fake, pred_traj_fake_rel,\n",
    "    loss_mask\n",
    "):\n",
    "    g_l2_loss_abs = l2_loss(\n",
    "        pred_traj_fake, pred_traj_gt, loss_mask, mode='sum'\n",
    "    )\n",
    "    g_l2_loss_rel = l2_loss(\n",
    "        pred_traj_fake_rel, pred_traj_gt_rel, loss_mask, mode='sum'\n",
    "    )\n",
    "    return g_l2_loss_abs, g_l2_loss_rel\n",
    "\n",
    "\n",
    "def cal_ade(pred_traj_gt, pred_traj_fake, linear_ped, non_linear_ped):\n",
    "    ade = displacement_error(pred_traj_fake, pred_traj_gt)\n",
    "    ade_l = displacement_error(pred_traj_fake, pred_traj_gt, linear_ped)\n",
    "    ade_nl = displacement_error(pred_traj_fake, pred_traj_gt, non_linear_ped)\n",
    "    return ade, ade_l, ade_nl\n",
    "\n",
    "\n",
    "def cal_fde(\n",
    "    pred_traj_gt, pred_traj_fake, linear_ped, non_linear_ped\n",
    "):\n",
    "    fde = final_displacement_error(pred_traj_fake[-1], pred_traj_gt[-1])\n",
    "    fde_l = final_displacement_error(\n",
    "        pred_traj_fake[-1], pred_traj_gt[-1], linear_ped\n",
    "    )\n",
    "    fde_nl = final_displacement_error(\n",
    "        pred_traj_fake[-1], pred_traj_gt[-1], non_linear_ped\n",
    "    )\n",
    "    return fde, fde_l, fde_nl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "traffino",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
